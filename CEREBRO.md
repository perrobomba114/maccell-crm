# ğŸ§  Cerebro â€” DocumentaciÃ³n TÃ©cnica Completa

> **Sistema de Inteligencia Artificial** integrado en el CRM de MACCELL para diagnÃ³stico tÃ©cnico de reparaciones de celulares. Esta documentaciÃ³n estÃ¡ destinada a programadores que necesiten entender, mantener o extender el sistema.

---

## Ãndice

1. [Arquitectura General](#1-arquitectura-general)
2. [Stack TecnolÃ³gico](#2-stack-tecnolÃ³gico)
3. [Flujo Completo de una Consulta](#3-flujo-completo-de-una-consulta)
4. [Modelos de IA y sus Roles](#4-modelos-de-ia-y-sus-roles)
5. [RAG â€” Base de Conocimiento SemÃ¡ntico](#5-rag--base-de-conocimiento-semÃ¡ntico)
6. [Vision Router](#6-vision-router)
7. [API Route `/api/cerebro/chat`](#7-api-route-apicerebrochat)
8. [Frontend â€” componente CerebroChat](#8-frontend--componente-cerebrochat)
9. [Base de Datos](#9-base-de-datos)
10. [Variables de Entorno](#10-variables-de-entorno)
11. [Scripts de Mantenimiento](#11-scripts-de-mantenimiento)
12. [CÃ³mo Extender Cerebro](#12-cÃ³mo-extender-cerebro)
13. [Troubleshooting](#13-troubleshooting)

---

## 1. Arquitectura General

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USUARIO (TÃ©cnico)                        â”‚
â”‚              Browser â†’ https://maccell.app/admin/cerebro        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚  WebSocket / HTTP Stream
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NEXT.JS (Vercel/Self-hosted)                 â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  src/components/cerebro/cerebro-chat.tsx                â”‚   â”‚
â”‚  â”‚  â€¢ TextStreamChatTransport (@ai-sdk/react)              â”‚   â”‚
â”‚  â”‚  â€¢ Manejo de archivos/imÃ¡genes (FileReader â†’ base64)    â”‚   â”‚
â”‚  â”‚  â€¢ Renderizado de mensajes con Markdown                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚ POST /api/cerebro/chat                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  src/app/api/cerebro/chat/route.ts                      â”‚   â”‚
â”‚  â”‚  1. Parsea mensajes del SDK                             â”‚   â”‚
â”‚  â”‚  2. RAG: busca tickets similares en pgvector            â”‚   â”‚
â”‚  â”‚  3. Vision Router: Â¿imagen es PCB?                      â”‚   â”‚
â”‚  â”‚  4. Llama a Ollama con el modelo correcto               â”‚   â”‚
â”‚  â”‚  5. Hace stream de la respuesta de vuelta               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                       â”‚
              â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL        â”‚   â”‚   OLLAMA SERVER (Windows / RTX 3090) â”‚
â”‚   (pgvector)        â”‚   â”‚   IP: 100.110.53.47:11434            â”‚
â”‚                     â”‚   â”‚                                      â”‚
â”‚  repair_embeddings  â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  (vectores 768d)    â”‚   â”‚  â”‚ deepseek-r1:14b  â†’ Chat texto   â”‚ â”‚
â”‚  â—„â”€â”€ bÃºsqueda       â”‚   â”‚  â”‚ llava:13b        â†’ Vision PCB   â”‚ â”‚
â”‚      coseno         â”‚   â”‚  â”‚ llama3.2:1b      â†’ Router (<1s) â”‚ â”‚
â”‚                     â”‚   â”‚  â”‚ nomic-embed-text â†’ Embeddings   â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Stack TecnolÃ³gico

| Capa | TecnologÃ­a | VersiÃ³n | Rol |
|---|---|---|---|
| Frontend | Next.js App Router | 15.x | SSR + API Routes |
| UI Chat | `@ai-sdk/react` `useChat` | 1.x | Hook de estado y streaming |
| Transport | `TextStreamChatTransport` | ai v4+ | EnvÃ­o de mensajes al backend |
| DB principal | PostgreSQL + Prisma | 6.x | Datos de reparaciones |
| DB vectorial | pgvector (ext. de PG) | 0.7+ | BÃºsqueda semÃ¡ntica |
| LLM Chat | deepseek-r1:14b | via Ollama | DiagnÃ³stico por texto |
| LLM VisiÃ³n | llava:13b | via Ollama | AnÃ¡lisis de imÃ¡genes PCB |
| LLM Router | llama3.2:1b | via Ollama | Clasificador binario |
| LLM Embed | nomic-embed-text | via Ollama | VectorizaciÃ³n RAG |
| LLM Enhancer | llama3.1:8b | via Ollama | Mejora de diagnÃ³sticos |
| Infraestructura | Ollama + RTX 3090 | local | Sin costo de API |

---

## 3. Flujo Completo de una Consulta

### 3A. Consulta de texto (sin imagen)

```
TIPO: TÃ©cnico escribe "a23 no enciende, consumo 80mA"
                          â”‚
                          â–¼
              [cerebro-chat.tsx]
              sendMessage({ parts: [{ type: 'text', text: '...' }] })
                          â”‚
                          â–¼ POST /api/cerebro/chat
              [route.ts â€” Parseo]
              Extrae text de message.parts[].text
                          â”‚
                          â–¼
              [route.ts â€” RAG]
              findSimilarRepairs("a23 no enciende consumo 80mA", limit=3)
                â€¢ Vectoriza query con nomic-embed-text
                â€¢ Busca por coseno en repair_embeddings (pgvector)
                â€¢ Devuelve tickets similares si similarity > 0.72
                          â”‚
              Si hay resultados:
              Inyecta en SYSTEM_PROMPT:
              "### BASE DE DATOS MACCELL â€” CASOS SIMILARES:
               [Caso 1 â€” Motorola A23 | Ticket: MAC1-170 | Similitud: 87%]
               DIAGNÃ“STICO: Cortocircuito en lÃ­nea PP_CPU_VDD..."
                          â”‚
                          â–¼
              [route.ts â€” Ollama deepseek-r1:14b]
              POST http://100.110.53.47:11434/api/chat
              { model: "deepseek-r1:14b",
                messages: [system, ...history(10), user],
                stream: true, temperature: 0.3 }
                          â”‚
                          â–¼ NDJSON stream de Ollama
              [route.ts â€” Stream adapter]
              Convierte NDJSON â†’ texto plano
                          â”‚
                          â–¼ text/plain stream
              [cerebro-chat.tsx]
              TextStreamChatTransport recibe y actualiza UI en tiempo real
```

### 3B. Consulta con imagen

```
TIPO: TÃ©cnico sube foto de placa + "a12 error de pantalla"
                          â”‚
                          â–¼
              [cerebro-chat.tsx]
              FileReader.readAsDataURL(file) â†’ base64 data URI
              sendMessage({ parts: [
                { type: 'text', text: 'a12 error de pantalla' },
                { type: 'file', file: { url: 'data:image/png;base64,...' } }
              ] })
                          â”‚
                          â–¼ POST /api/cerebro/chat
              [route.ts â€” Parseo]
              Extrae text de parts[0].text
              Extrae base64 de parts[1].file.url.split(',')[1]
                          â”‚
                          â–¼
              [route.ts â€” Vision Router]
              isElectronicBoard(base64)
                â€¢ usa llama3.2:1b (ultrarrÃ¡pido ~1s)
                â€¢ pregunta: "Does this image show a PCB? YES or NO"
                          â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ NO es PCB             â”‚ SÃ es PCB
              â–¼                       â–¼
         Response inmediata:    [route.ts â€” Ollama llava:13b]
         "âš ï¸ Imagen no        POST .../api/chat
          tÃ©cnica detectada"   { model: "llava:13b",
                                 messages: [
                                   system: VISION_PROMPT + "tÃ©cnico indicÃ³: ...",
                                   user: { content: text, images: [base64] }
                                 ],
                                 stream: true,
                                 temperature: 0,
                                 num_predict: 250,
                                 repeat_penalty: 1.5 }
                                        â”‚
                                        â–¼ stream de respuesta visual
```

---

## 4. Modelos de IA y sus Roles

### ConfiguraciÃ³n centralizada
**Archivo:** `src/config/ai-models.ts`

```typescript
export const OLLAMA_MODELS = {
    CHAT: "deepseek-r1:14b",        // Chat principal de diagnÃ³stico
    VISION: "llava:13b",            // AnÃ¡lisis de imÃ¡genes de placas
    ROUTER: "llama3.2:1b",          // Clasificador binario (PCB sÃ­/no)
    EMBED: "nomic-embed-text",      // VectorizaciÃ³n para RAG
    ENHANCER: "llama3.1:8b",        // Mejora automÃ¡tica de diagnÃ³sticos
    DEEP_REASONING: "deepseek-r1:14b", // Cron nocturno de enriquecimiento
}
```

### Â¿Por quÃ© estos modelos?

| Modelo | RAM GPU | Latencia | Fortaleza |
|---|---|---|---|
| `deepseek-r1:14b` | ~8GB | 3-8s | Razonamiento lÃ³gico, sigue estructura de respuesta |
| `llava:13b` | ~8GB | 5-15s | VisiÃ³n + menos alucinaciÃ³n que llama3.2-vision |
| `llama3.2:1b` | ~1GB | <1s | ClasificaciÃ³n binaria rapidÃ­sima |
| `nomic-embed-text` | ~500MB | ~100ms | Embeddings de 768d, alta calidad semÃ¡ntica |
| `llama3.1:8b` | ~5GB | 2-5s | Instrucciones precisas, mejora de redacciÃ³n |

---

## 5. RAG â€” Base de Conocimiento SemÃ¡ntico

### Â¿QuÃ© es RAG en Cerebro?

RAG (Retrieval-Augmented Generation) permite que Cerebro responda basÃ¡ndose en **reparaciones reales de MACCELL** en lugar de inventar respuestas genÃ©ricas.

**Sin RAG:** "El A23 podrÃ­a tener un problema en el sistema de alimentaciÃ³n..."  
**Con RAG:** "SegÃºn Ticket #MAC1-170 (87% similar): El A23 con ese consumo tuvo cortocircuito en PP_CPU_VDD. SoluciÃ³n: reballing del PMIC."

### Archivos involucrados

```
src/actions/cerebro-rag.ts          â† LÃ³gica de bÃºsqueda semÃ¡ntica
scripts/index-repairs-full.js       â† IndexaciÃ³n inicial del historial
scripts/setup-pgvector.sql          â† Setup de la tabla vectorial
scripts/index-repairs.ts            â† VersiÃ³n TypeScript del indexador
```

### Tabla `repair_embeddings` en PostgreSQL

```sql
CREATE TABLE repair_embeddings (
    id            TEXT PRIMARY KEY,
    "repairId"    TEXT UNIQUE NOT NULL,  -- FK lÃ³gica a repairs.id
    "ticketNumber" TEXT NOT NULL,
    "deviceBrand" TEXT NOT NULL,
    "deviceModel" TEXT NOT NULL,
    "contentText" TEXT NOT NULL,         -- Documento completo indexado
    embedding     vector(768),           -- pgvector: nomic-embed-text output
    "createdAt"   TIMESTAMPTZ,
    "updatedAt"   TIMESTAMPTZ
);
-- Ãndice HNSW para bÃºsqueda coseno en <10ms
CREATE INDEX repair_embeddings_hnsw_idx
    ON repair_embeddings USING hnsw (embedding vector_cosine_ops);
```

### Â¿QuÃ© se vectoriza?

Por cada reparaciÃ³n se construye un documento como este:

```
TICKET: MAC1-170
DISPOSITIVO: Motorola A23
SUCURSAL: San Luis Centro
ESTADO: Finalizado
FECHA INGRESO: 15/01/2025
TIEMPO DE REPARACIÃ“N: 3 dÃ­a(s)
CONDICIÃ“N: INGRESÃ“ CON HUMEDAD/AGUA

PROBLEMA REPORTADO:
El equipo no enciende. Cliente dice que se cayÃ³ al agua.

DIAGNÃ“STICO TÃ‰CNICO:
Cortocircuito en lÃ­nea PP_CPU_VDD. Se midiÃ³ 000mV en escala de diodo.
Reballing del PMIC. El equipo funcionÃ³ correctamente.

OBSERVACIONES DEL TÃ‰CNICO:
â€¢ Se limpiÃ³ con ultrasonido antes de medir
â€¢ Se verificÃ³ baterÃ­a: 3.85V OK

REPUESTOS USADOS:
â€¢ PMIC Motorola G Series (Qualcomm) x1
```

### Flujo de bÃºsqueda RAG

```typescript
// 1. Vectorizar la pregunta del tÃ©cnico
const embedding = await embedQuery("a23 no enciende consumo 80mA", "nomic-embed-text")

// 2. BÃºsqueda por similitud coseno en pgvector
const results = await pool.query(`
    SELECT "ticketNumber", "deviceBrand", "deviceModel", "contentText",
           1 - (embedding <=> $1::vector) AS similarity
    FROM repair_embeddings
    WHERE 1 - (embedding <=> $1::vector) >= 0.72  -- umbral de similitud
    ORDER BY embedding <=> $1::vector
    LIMIT 3
`, [vectorStr])

// 3. Formatear como contexto para el prompt
// â†’ "### BASE DE DATOS MACCELL â€” CASOS SIMILARES: [Caso 1 â€” ...]"

// 4. Concatenar al SYSTEM_PROMPT antes de llamar a Ollama
```

---

## 6. Vision Router

### Problema que resuelve

Los modelos de visiÃ³n grandes (llava:13b, llama3.2-vision) tienden a **alucinar**: si mandÃ¡s el escudo de la AFA o el logo de Apple, el modelo dice que es una "placa electrÃ³nica con daÃ±os". Esto ocurre porque son modelos generativos que intentan ser "Ãºtiles" aunque no vean lo que el prompt describe.

### SoluciÃ³n: clasificador previo

Antes de llamar al modelo caro (llava:13b, ~8s), llamamos a un modelo ultrapequeÃ±o (`llama3.2:1b`, ~1s) que solo responde `YES` o `NO`:

```typescript
async function isElectronicBoard(base64Image: string): Promise<boolean> {
    // Llama a llama3.2:1b con temperature:0 y num_predict:5
    // Pregunta: "Does this image show a PCB? Answer ONLY YES or NO"
    // Si dice YES â†’ continÃºa con llava:13b
    // Si dice NO  â†’ devuelve mensaje inmediato sin llamar al modelo caro
    // Si hay error â†’ falla abierta (deja pasar, no bloquea)
}
```

### Beneficios

- **Ahorro de VRAM**: llama3.2:1b usa ~1GB vs ~8GB de llava:13b
- **5-10x mÃ¡s rÃ¡pido** para rechazos
- **Sin alucinaciones** en imÃ¡genes no tÃ©cnicas
- **Fail-open**: si el router falla, el anÃ¡lisis continÃºa normalmente

---

## 7. API Route `/api/cerebro/chat`

**Archivo:** `src/app/api/cerebro/chat/route.ts`

### Endpoint

```
POST /api/cerebro/chat
Content-Type: application/json

{
  "id": "conversation-id",
  "messages": [
    {
      "role": "user",
      "parts": [
        { "type": "text", "text": "a23 no enciende" },
        { "type": "file", "file": { "url": "data:image/png;base64,..." } }
      ]
    }
  ],
  "trigger": "submit-message"
}
```

### Respuesta

```
HTTP/1.1 200 OK
Content-Type: text/plain; charset=utf-8

### ğŸ“‚ REFERENCIA HISTÃ“RICA (Maccell DB)
- Se encontrÃ³ coincidencia en Ticket #MAC1-170...

### ğŸ” ANÃLISIS DE CONSUMO...
```

Stream de texto plano (compatible con `TextStreamChatTransport`).

### LÃ³gica interna (pseudocÃ³digo)

```
POST(req) {
  messages = await req.json().messages
  
  // 1. Mapear mensajes SDK â†’ formato Ollama
  ollamaMessages = messages.map(m => {
    text = m.parts.filter(type='text').join()
           || m.content  // fallback
    images = m.parts.filter(type='file').map(extractBase64)
    return { role, content: text, images }
  }).filter(hasContent)
  
  history = ollamaMessages.slice(-10)  // Ãºltimos 10
  lastUser = history.reverse().find(role='user')
  hasImages = lastUser.images?.length > 0
  
  if hasImages:
    // Vision Router
    isPCB = await isElectronicBoard(lastUser.images[0])
    if !isPCB: return "âš ï¸ No es placa" (inmediato)
    
    // VisiÃ³n con llava:13b (sin historial, solo imagen actual)
    messages = [
      { role:'system', content: VISION_PROMPT + userText },
      { role:'user', content: userText, images: lastUser.images }
    ]
  else:
    // RAG: buscar reparaciones similares
    ragContext = await findSimilarRepairs(lastUser.content)
    systemPrompt = SYSTEM_PROMPT + ragContext
    
    history.unshift({ role:'system', content: systemPrompt })
    messages = history
  
  // Llamar a Ollama y hacer streaming
  ollamaResponse = fetch(OLLAMA_URL/api/chat, { stream:true, ... })
  
  // Adaptar NDJSON â†’ texto plano
  stream = ollamaResponse.body
    .parse each line as JSON
    .extract parsed.message.content
    .encode as UTF-8 bytes
  
  return Response(stream, { 'Content-Type': 'text/plain' })
}
```

---

## 8. Frontend â€” componente CerebroChat

**Archivo:** `src/components/cerebro/cerebro-chat.tsx`

### Hook principal

```typescript
const { messages, sendMessage, stop, status, error } = useChat({
    id: conversationId,
    messages: initialMessages,  // del servidor (historial de DB)
    transport: new TextStreamChatTransport({ api: "/api/cerebro/chat" }),
    onFinish: async ({ message, messages }) => {
        // Guarda mensajes en DB (cerebroMessages)
        await saveMessagesToDbAction(conversationId, messages)
        // Genera tÃ­tulo automÃ¡tico si es la primera vez
        if (messages.length === 2) await updateConversationTitleAction(...)
    },
    onError: (err) => toast.error(err.message)
})
```

### Â¿Por quÃ© `TextStreamChatTransport` y no `DefaultChatTransport`?

El backend devuelve **texto plano puro** (no el protocolo `0:"texto"\n` de Vercel). `TextStreamChatTransport` es el transport correcto para este caso:

| Transport | Formato esperado del backend |
|---|---|
| `DefaultChatTransport` | `0:"texto"\n` (Vercel Data Stream Protocol) |
| `TextStreamChatTransport` | texto plano (compatible con Ollama directo) |

### EnvÃ­o de mensajes con imÃ¡genes

```typescript
// Las imÃ¡genes NO van como experimental_attachments
// Van dentro del array parts como type:'file'
const parts = [
    { type: 'text', text: userInput },
    { type: 'file', file: { name, type, url: base64DataURI } }
]
sendMessage({ parts })

// En route.ts, se extrae asÃ­:
// part.type === 'file' && part.file.url.startsWith('data:image')
```

**Â¿Por quÃ© no `experimental_attachments`?**  
Con `TextStreamChatTransport`, el segundo argumento de `sendMessage` no se serializa en el body. Solo `parts` llega al servidor.

---

## 9. Base de Datos

### Modelos Prisma relacionados con Cerebro

```prisma
// Conversaciones de Cerebro (una por sesiÃ³n de trabajo del tÃ©cnico)
model CerebroConversation {
  id        String           @id
  userId    String
  title     String?          // Generado automÃ¡ticamente por la IA
  messages  CerebroMessage[]
}

// Mensajes individuales (persisten entre sesiones)
model CerebroMessage {
  id             String @id
  conversationId String
  role           String  // 'user' | 'assistant'
  content        String
  mediaUrls      String[] // URLs de imÃ¡genes adjuntas
}

// Embeddings vectoriales para RAG (gestionado con SQL raw)
// Tabla: repair_embeddings (no en schema Prisma, se maneja con pg Pool directo)
```

### Â¿Por quÃ© `repair_embeddings` no estÃ¡ en Prisma?

Prisma no soporta nativo el tipo `vector(768)` de pgvector. Se usa `pg.Pool` con SQL directo para:
- INSERT/UPSERT de embeddings
- BÃºsqueda por similitud coseno (`<=>` operator de pgvector)
- CREATE INDEX HNSW

Todo lo demÃ¡s usa el PrismaClient normal.

---

## 10. Variables de Entorno

```bash
# .env

# Base de datos PostgreSQL (misma DB del CRM)
DATABASE_URL="postgresql://user:pass@host:5432/maccell_db"

# Servidor Ollama (Windows con RTX 3090, acceso vÃ­a Tailscale)
OLLAMA_BASE_URL="http://100.110.53.47:11434"

# Nota: NO hay API keys de OpenAI ni Anthropic.
# Todo corre local en la red de MACCELL.
```

---

## 11. Scripts de Mantenimiento

### Setup inicial (una sola vez)

```bash
# 1. Habilitar pgvector en PostgreSQL
psql -d maccell_db -f scripts/setup-pgvector.sql

# 2. Descargar modelos en el servidor Ollama (PowerShell Windows)
ollama pull llava:13b
ollama pull llama3.2:1b
ollama pull nomic-embed-text

# 3. Indexar historial completo de reparaciones
node scripts/index-repairs-full.js
```

### Mantenimiento regular

```bash
# Indexar solo reparaciones nuevas (correr semanalmente o con cron)
node scripts/index-repairs-full.js --only-new

# Reiniciar toda la base vectorial (si se cambia el modelo de embeddings)
node scripts/index-repairs-full.js --reset

# Revisar un ticket especÃ­fico
node scripts/index-repairs-full.js --ticket MAC1-170

# Ver cuÃ¡ntos vectores hay en la DB
psql -d maccell_db -c "SELECT COUNT(*) FROM repair_embeddings;"
```

### Opciones del script

| Flag | DescripciÃ³n |
|---|---|
| *(sin flags)* | Indexa todas las reparaciones con diagnÃ³stico |
| `--only-new` | Solo indexa las que no tienen embedding aÃºn |
| `--reset` | Borra todo y reindexar completo |
| `--ticket X` | Indexa solo el ticket nÃºmero X |

---

## 12. CÃ³mo Extender Cerebro

### Agregar un nuevo modelo de IA

1. Descargar con `ollama pull new-model:7b` en el servidor Windows
2. Agregar en `src/config/ai-models.ts`:
   ```typescript
   NUEVO_ROL: "new-model:7b",
   ```
3. Usar en `route.ts`: `OLLAMA_MODELS.NUEVO_ROL`

### Cambiar el SYSTEM_PROMPT

Editar la constante `SYSTEM_PROMPT` en `src/app/api/cerebro/chat/route.ts`. El prompt usa markdown porque `deepseek-r1:14b` lo respeta en la salida.

**Estructura del SYSTEM_PROMPT actual:**
1. DescripciÃ³n de rol y contexto
2. Protocolo de consulta a DB
3. Estructura obligatoria de respuesta (5 secciones con emojis)
4. Triada de ingreso MACCELL (para datos insuficientes)
5. TerminologÃ­a tÃ©cnica requerida

### Cambiar umbrales del RAG

En `src/app/api/cerebro/chat/route.ts`:
```typescript
const similarRepairs = await findSimilarRepairs(userQuery, 3, 0.72);
//                                                          â†‘  â†‘
//                                                    limit  min_similarity
```

- `limit`: cuÃ¡ntos casos similares inyectar (3 es un buen balance)
- `min_similarity`: umbral 0.72 = 72% de similitud coseno mÃ­nima

Si bajÃ¡s el umbral (e.g. 0.60), el RAG es mÃ¡s "generoso" pero trae casos menos relevantes.

### Agregar otro endpoint de Cerebro (ej: Cerebro visual de esquemÃ¡ticos)

1. Crear `src/app/api/cerebro/schematics/route.ts`
2. Importar los modelos desde `@/config/ai-models`
3. Usar un VISION_PROMPT especÃ­fico para esquemÃ¡ticos
4. El frontend puede usar otro `useChat` con `api: "/api/cerebro/schematics"`

---

## 13. Troubleshooting

### El chat no responde nada

1. **Verificar Ollama:** `curl http://100.110.53.47:11434/api/tags` â€” debe devolver lista de modelos
2. **Verificar que el modelo estÃ¡ descargado:** la respuesta debe incluir `deepseek-r1:14b`
3. **Verificar red Tailscale:** hacer ping al servidor desde la Mac
4. **Console del browser:** buscar errores en la pestaÃ±a Network â†’ `/api/cerebro/chat`

### El chat responde pero ignora el mensaje del usuario

SÃ­ntoma: siempre responde con la "Triada de ingreso MACCELL" sin importar quÃ© se escriba.

Causa probable: el campo `parts` del mensaje llega vacÃ­o al backend.

Debug:
```typescript
// Agregar en route.ts temporalmente:
console.log("BODY:", JSON.stringify(await req.json()).substring(0, 500))
```

### Las imÃ¡genes no se analizan

1. Verificar que `llava:13b` estÃ¡ descargado: `ollama list | grep llava`
2. Verificar que el Vision Router (`llama3.2:1b`) tambiÃ©n estÃ¡ descargado
3. Revisar logs: buscar `[CEREBRO_ROUTER]` â€” si no aparece, la imagen no llega como `parts`

### El RAG no incluye casos similares

1. Verificar que pgvector estÃ¡ activo: `SELECT * FROM pg_extension WHERE extname='vector';`
2. Verificar que la tabla tiene datos: `SELECT COUNT(*) FROM repair_embeddings;`
3. Si estÃ¡ vacÃ­a: ejecutar `node scripts/index-repairs-full.js`
4. Verificar que `nomic-embed-text` estÃ¡ en Ollama: `ollama list | grep nomic`

### La respuesta se corta / trunca

El parÃ¡metro `num_predict: 1024` controla el mÃ¡ximo de tokens. Para respuestas mÃ¡s largas:
```typescript
// En route.ts
num_predict: hasImagesInLastMessage ? 250 : 2048,  // aumentar para texto
```

### El modelo de visiÃ³n alucina en imÃ¡genes tÃ©cnicas reales

El Vision Router dijo `YES` (es PCB) pero el modelo describe cosas incorrectas.

Opciones:
1. Mejorar la foto (mÃ¡s luz, mÃ¡s foco en el Ã¡rea daÃ±ada)
2. Ajustar `VISION_PROMPT` para ser mÃ¡s especÃ­fico
3. Considerar subir a `llava:34b` si el hardware lo permite (requiere ~20GB VRAM)

---

## Estructura de Archivos

```
src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/cerebro/chat/
â”‚   â”‚   â””â”€â”€ route.ts              â† API endpoint principal de Cerebro
â”‚   â”œâ”€â”€ admin/cerebro/
â”‚   â”‚   â””â”€â”€ page.tsx              â† PÃ¡gina de Cerebro para admins
â”‚   â””â”€â”€ technician/cerebro/
â”‚       â””â”€â”€ page.tsx              â† PÃ¡gina de Cerebro para tÃ©cnicos
â”œâ”€â”€ components/cerebro/
â”‚   â”œâ”€â”€ cerebro-chat.tsx          â† Componente de chat (frontend)
â”‚   â””â”€â”€ cerebro-layout.tsx        â† Layout con sidebar de historial
â”œâ”€â”€ actions/
â”‚   â”œâ”€â”€ cerebro-actions.ts        â† Server actions (DB: conversations, messages)
â”‚   â””â”€â”€ cerebro-rag.ts            â† BÃºsqueda semÃ¡ntica con pgvector
â””â”€â”€ config/
    â””â”€â”€ ai-models.ts              â† ConfiguraciÃ³n centralizada de modelos

scripts/
â”œâ”€â”€ setup-pgvector.sql            â† Setup inicial de pgvector (una vez)
â”œâ”€â”€ index-repairs-full.js         â† Indexador completo de reparaciones
â””â”€â”€ index-repairs.ts              â† VersiÃ³n TypeScript del indexador

prisma/
â””â”€â”€ schema.prisma                 â† Modelos: Repair, RepairEmbedding,
                                    CerebroConversation, CerebroMessage
```

---

## Diagrama de DecisiÃ³n del Route

```
                    POST /api/cerebro/chat
                           â”‚
                    Parsear mensajes
                    Extraer texto + base64
                           â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
             Â¿Tiene imÃ¡genes?
             â”‚               â”‚
            SÃ              NO
             â”‚               â”‚
     Vision Router          RAG
     llama3.2:1b    findSimilarRepairs()
             â”‚               â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”   Inyectar tickets
      â”‚ NO es PCB   â”‚   similares en prompt
      â–¼             â”‚             â”‚
  Respuesta         SÃ           â”‚
  inmediata         â”‚             â”‚
  "No es placa"     â–¼             â–¼
                llava:13b    deepseek-r1:14b
                VISION_PROMPT SYSTEM_PROMPT
                temp=0        temp=0.3
                num_pred=250  num_pred=1024
                repeat=1.5    repeat=1.1
                    â”‚             â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                    Stream texto plano
                    â†’ TextStreamChatTransport
                    â†’ useChat() actualiza UI
```

---

*DocumentaciÃ³n generada: Febrero 2026 | MACCELL CRM â€” Sistema Cerebro AI*
