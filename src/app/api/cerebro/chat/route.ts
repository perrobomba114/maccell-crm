import { NextRequest } from "next/server";
import { createGroq } from "@ai-sdk/groq";
import { streamText, generateText } from "ai";
import { trackTokens } from "@/lib/cerebro-token-tracker";
import { findSimilarRepairs, formatRAGContext } from "@/lib/cerebro-rag";
import { findSchematic, formatSchematicContext } from "@/lib/cerebro-schematics";
import { LEVEL3_MASTER_KNOWLEDGE } from "@/lib/master-protocols";
import pdfParse from "pdf-parse";
import { getGroqKeys } from "@/lib/groq";


// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// CONFIGURACIÃ“N
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const MAX_HISTORY_MSGS = 10;
const MAX_MSG_CHARS = 800;
const MAX_OUTPUT_TOKENS = 800;
const MAX_PDF_CHARS = 8000;
const MAX_IMAGES = 4;

export const maxDuration = 60;
export const dynamic = 'force-dynamic';

const TIMEOUTS = {
    classify: 2500,
    schematic: 3000,
    rag: 3000,
    diagnostic: 5000,
} as const;

interface CerebroRequestBody {
    messages: any[];
    guidedMode?: boolean;
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// MODELOS
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const TEXT_MODELS = [
    { label: 'Llama 3.3 70B', id: 'llama-3.3-70b-versatile' },
    { label: 'Llama 3.1 8B', id: 'llama-3.1-8b-instant' },
];
const VISION_MODEL = { label: 'Llama 3.2 11B Vision', id: 'llama-3.2-11b-vision-preview' };
const DIAG_EXTRACT_MODEL = 'llama-3.1-8b-instant';

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// PROMPTS
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const BASE_INSTRUCTIONS = `## âš“ PROTOCOLO DE VERIFICACIÃ“N (EJECUTAR ANTES DE RESPONDER)
Antes de generar cualquier nombre de componente (U, L, C, R):
1. Â¿Existe en ### ğŸ“‚ DATOS EXTRAÃDOS DEL PLANO? â†’ Usalo.
2. Â¿No existe? â†’ UsÃ¡ SOLO el bloque funcional genÃ©rico: "IC de carga", "Buck del sistema".
3. PROHIBIDO: Inferir o "completar" IDs por analogÃ­a con otros dispositivos.

### ğŸŸ¡ PROTOCOLO DE INCERTIDUMBRE:
Si el dato no estÃ¡ en el contexto provisto, la Ãºnica respuesta vÃ¡lida es:
"No tengo confirmaciÃ³n de esquema para ese componente. MedÃ­ el Rail [X] en el TP mÃ¡s cercano y reportÃ¡."
NUNCA completar con memoria de otros modelos de placa.

### ğŸ“Œ FORMATO OBLIGATORIO PARA COMPONENTES:
Cada componente citado DEBE seguir esta plantilla:
- âœ… [NOMBRE_IC] â€” Fuente: [Ticket XXX / Plano adjunto / Rail medido]
- âŒ Si no tenÃ©s fuente â†’ escribÃ­: "[Bloque funcional sin ID confirmada]"

---

ActuÃ¡ como Cerebro AI, un Ingeniero Senior de Nivel 3. 
Tu lenguaje es tÃ©cnico puro y enfocado en microsoldadura y arquitectura de hardware.

### ğŸ› ï¸ RESTRICCIONES DE LABORATORIO:
- Herramientas: MultÃ­metro, Fuente, Rosin, Microscopio, EstaciÃ³n de soldadura.
- PROHIBIDO: Sugerir Osciloscopio o CÃ¡mara TÃ©rmica. Sustituir siempre por MultÃ­metro.

### ğŸš« REGLAS DE ORO (FALLO SI SE INCUMPLEN):
- NO incluyas "Notas", "Advertencias", "Cuidado" o comentarios sobre dificultad.
- NO sugieras "limpiar el sensor" o "limpieza de contactos" ni update de SW.
- NO des consejos de seguridad o experiencia previa. El usuario es un experto experto.
- NO agregues introducciones, despedidas ni textos fuera de las secciones solicitadas.

### ğŸ”¬ MODO SOCIO EXPERTO:
El usuario es un Master con 10+ aÃ±os. No des consejos bÃ¡sicos.
1. Enfocate en ICs (U-series), Bobinas (L), Capacitores (C) y Test Points.
2. UsÃ¡ valores de CaÃ­da de TensiÃ³n (mV) y Voltajes (V).
3. **JERARQUÃA DE FUENTES (Obligatoria)**:
   1Â° â†’ ### ğŸ“‚ DATOS EXTRAÃDOS DEL PLANO (Prioridad MÃ¡xima)
   2Â° â†’ ### ğŸ“š HISTORIAL DE REPARACIONES REALES (Usalo como ancla principal)
   3Â° â†’ Tu conocimiento base interno.

### ğŸ›‘ REGLAS DE ESCALADA (Solicitar datos faltantes):
Si los datos son insuficientes, solicitÃ¡ 1 dato crÃ­tico en 1 lÃ­nea (ej. "Â¿Modelo de placa y valor en VDD_MAIN con fuente a 4V?").
- TRIGGER A: Sin modelo de dispositivo especificado.
- TRIGGER B: SÃ­ntoma ambiguo (ej. "No enciende") y 0 valores de mediciÃ³n.
- TRIGGER C: Contexto contradictorio (ej. "15V en lÃ­nea de 3.3V").
Si hay suficientes datos, NO escale.

### ğŸ‡¦ğŸ‡· DICCIONARIO DE TALLER (JERGA LOCAL):
- **MÃ“DULO**: Se refiere ÃšNICAMENTE a la Pantalla/Display/LCD/OLED. 
- **MÃ“DULO DE CARGA**: Se refiere a la Sub-placa de carga/Pin de carga.
- **NUNCA** interpretes "MÃ³dulo" como "MÃ³dulo de cÃ¡mara" si el contexto es de Imagen o Encendido. Si se cambiÃ³ el mÃ³dulo por falta de imagen, se cambiÃ³ la PANTALLA.`;

const STANDARD_PROMPT = `${BASE_INSTRUCTIONS}

### ğŸ§  CONOCIMIENTO MAESTRO:
${LEVEL3_MASTER_KNOWLEDGE}

### ESTRUCTURA DE RESPUESTA (OBLIGATORIA):
1. **AnÃ¡lisis Diferencial**: HipÃ³tesis con %.
2. **Estado del Sistema**: RaÃ­les crÃ­ticos (VBUS, VDD, etc).
3. **Protocolo de MediciÃ³n**: Pasos con multÃ­metro/fuente.
4. **AcciÃ³n**: IntervenciÃ³n fÃ­sica (trasplante, reballing, jumper).

### ğŸ FINALIZACIÃ“N CRÃTICA:
La respuesta DEBE TERMINAR inmediatamente despuÃ©s del punto 4 (AcciÃ³n). Cualquier palabra posterior serÃ¡ considerada un error de protocolo.`;

const MENTOR_PROMPT = `${BASE_INSTRUCTIONS}

### ğŸ§  CONOCIMIENTO MAESTRA:
${LEVEL3_MASTER_KNOWLEDGE}

### ğŸ”¬ MODO SOCIO (PARTNER-TECH):
Trabajamos paso a paso. Yo te guÃ­o en la mediciÃ³n, vos me das los valores. 
- UNA SOLA mediciÃ³n especÃ­fica por turno.
- EnseÃ±Ã¡ a interpretar los resultados: explicÃ¡ quÃ© significa el valor esperado vs el obtenido.
- Usamos terminologÃ­a pura (VPH_PWR, Rails, Buck, LDO).`;

const ACADEMY_PROMPT = `ActuÃ¡ como un Instructor Master de Microsoldadura. 
Tu objetivo es que un tÃ©cnico Nivel 1 entienda la lÃ³gica del circuito antes de tocar la placa.

### ğŸ“š MÃ‰TODO DE ENSEÃ‘ANZA (4 PASOS):
1. **ARQUITECTURA DEL BLOQUE**: ExplicÃ¡ quÃ© voltajes (LDO/Buck) alimentan ese sector. 
   - UsÃ¡ "cascadas" de texto para visualizar el flujo de energÃ­a (PMIC -> LDO -> CPU).
2. **HISTORIAL DE REPARACIONES (PRIORIDAD)**: 
   - SI hay ### ğŸ“š HISTORIAL, mencionÃ¡: "En reparaciones anteriores (Ticket XXX), la soluciÃ³n fue...". UsÃ¡ casos reales como ancla pedagÃ³gica.
3. **TÃ‰CNICA DE MEDICIÃ“N**: ExplicÃ¡ CÃ“MO medir, no solo quÃ© medir. (ej. "Punta roja a GND para caÃ­da de tensiÃ³n"). Aclarar polaridad y contexto.
4. **INTERPRETACIÃ“N DE RESULTADOS**: ExplicÃ¡ el significado del valor (OL = LÃ­nea Abierta, 0V = Corto, etc).
   - UsÃ¡ analogÃ­as: "El LDO es una canilla de voltaje", "El Buck es un compresor".

### ğŸš« REGLAS PEDAGÃ“GICAS:
- NO des la soluciÃ³n final (ej. "CambiÃ¡ el IC") de inmediato.
- ForzÃ¡ al tÃ©cnico a reportar UNA mediciÃ³n antes de avanzar. Terminar con: "Â¿CuÃ¡l es el valor que mediste?"
- **ESTRICTO**: Si no hay un esquemÃ¡tico real adjunto, NUNCA inventes U1, L1. HablÃ¡ de bloques genÃ©ricos.`;

const FINAL_DIRECTIVE = `
### âœ… PROTOCOLO DE VALIDACIÃ“N FINAL (Checklist Interno):
Antes de emitir el output, verificÃ¡ silenciosamente:
1. NingÃºn IC inventado sin fuente (corregir a bloque genÃ©rico si es falso).
2. 0 uso de Osciloscopio/TÃ©rmica (reemplazado por multÃ­metro).
3. 0 advertencias de "cuidado" o "limpieza".
4. La respuesta finaliza seco en la Ãºltima directiva.

RespondÃ© quirÃºrgicamente. Las instrucciones de estructura son absolutas.`;

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// UTILIDADES
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function truncate(text: string, max = MAX_MSG_CHARS): string {
    if (!text) return "";
    return text.length <= max ? text : text.slice(0, max) + '...';
}

async function extractPdfText(dataUrl: string): Promise<string | null> {
    try {
        const base64 = dataUrl.split(',')[1];
        if (!base64) return null;
        const buffer = Buffer.from(base64, 'base64');
        const parsed = await pdfParse(buffer);
        let text = parsed.text?.trim() || "";
        if (!text) return null;

        // PRIORIZACIÃ“N: Buscamos tÃ©rminos crÃ­ticos para que la IA no invente
        const keywords = ["camera", "ldo", "buck", "vcc", "mipi", "u3300", "u2700", "j_cam", "charger", "display", "backlight"];
        const lines = text.split('\n');
        const relevantLines = lines.filter(line =>
            keywords.some(kw => line.toLowerCase().includes(kw))
        ).slice(0, 40); // Tomamos las 40 lÃ­neas mÃ¡s importantes

        const prioritized = `### ğŸ“‚ DATOS EXTRAÃDOS DEL PLANO:\n${relevantLines.join('\n')}\n\n`;
        const fullContent = prioritized + text;

        return fullContent.length > MAX_PDF_CHARS
            ? fullContent.slice(0, MAX_PDF_CHARS) + '...'
            : fullContent;
    } catch (err: any) {
        console.warn('[CEREBRO] âš ï¸ Error parseando PDF:', err.message);
        return null;
    }
}

function extractImages(message: any): string[] {
    const images: string[] = [];
    if (Array.isArray(message.parts)) {
        for (const part of message.parts) {
            if (part.type === 'image' && part.image) {
                images.push(part.image);
            }
        }
    }
    return images.slice(0, MAX_IMAGES);
}

function lastUserText(message: any): string {
    if (typeof message.content === 'string') return message.content;
    if (Array.isArray(message.parts)) {
        return message.parts.filter((p: any) => p.type === 'text').map((p: any) => p.text).join(' ');
    }
    return "";
}

async function withTimeout<T>(promise: Promise<T>, ms: number, fallback: T): Promise<T> {
    return Promise.race([
        promise,
        new Promise<T>((resolve) => setTimeout(() => resolve(fallback), ms))
    ]);
}

async function normalizeHistory(messages: any[]): Promise<any[]> {
    const result: any[] = [];
    for (const m of messages) {
        let textContent = '';
        if (typeof m.content === 'string' && m.content.trim()) textContent = m.content;
        if (Array.isArray(m.parts)) {
            textContent = m.parts.filter((p: any) => p.type === 'text').map((p: any) => p.text).join(' ');
        }
        if (Array.isArray(m.content)) {
            textContent = m.content.filter((c: any) => c.type === 'text').map((c: any) => c.text).join(' ');
        }
        const finalText = truncate(textContent.trim());
        result.push({ role: m.role, content: finalText || (m.role === 'user' ? 'MediciÃ³n solicitada' : '...') });
    }
    return result;
}

async function parseLastMessage(msg: any): Promise<{ text: string, pdfTexts: string[] }> {
    let textContent = '';
    const pdfTexts: string[] = [];
    if (Array.isArray(msg.parts)) {
        for (const p of msg.parts) {
            if (p.type === 'text' && p.text) textContent += p.text + ' ';
            if (p.type === 'file') {
                const mt = p.mediaType || p.file?.mediaType || '';
                const url = p.url || p.file?.url || '';
                if (mt === 'application/pdf' && url) {
                    const pdf = await extractPdfText(url);
                    if (pdf) pdfTexts.push(pdf);
                }
            }
        }
    }
    if (typeof msg.content === 'string' && msg.content.trim()) textContent = msg.content;
    if (Array.isArray(msg.content)) {
        textContent = msg.content.filter((c: any) => c.type === 'text').map((c: any) => c.text).join(' ');
    }
    textContent = truncate(textContent.trim());
    return { text: textContent, pdfTexts };
}

async function buildVisionMessages(coreMessages: any[], images: string[]): Promise<any[]> {
    const lastMsg = coreMessages[coreMessages.length - 1];
    let text = "AnalizÃ¡ esta imagen tÃ©cnica.";
    const rawContent = typeof lastMsg?.content === 'string' ? lastMsg.content : lastUserText(lastMsg);
    if (rawContent) text = rawContent;

    const content: any[] = [{ type: 'text', text }];
    for (const img of images) {
        content.push({ type: 'image', image: img });
    }
    return [{ role: 'user', content }];
}

async function toCoreMsgs(messages: any[]): Promise<any[]> {
    try {
        const lastMsg = messages[messages.length - 1];
        const history = messages.slice(0, -1).slice(-MAX_HISTORY_MSGS + 1);

        const result = await normalizeHistory(history);

        const { text, pdfTexts } = await parseLastMessage(lastMsg);
        let finalContent = text;
        if (pdfTexts.length > 0) {
            const pdfBlock = pdfTexts.map((t, i) => `\n\nğŸ“„ [SCHEMATIC/PDF #${i + 1}]:\n${t}`).join('\n');
            finalContent = finalContent + pdfBlock;
        }

        result.push({ role: lastMsg.role, content: finalContent || (lastMsg.role === 'user' ? 'Analizar' : '...') });
        return result;
    } catch (e) {
        console.error("[CEREBRO] toCoreMsgs error:", e);
        return [{ role: 'user', content: 'Error procesando mensajes' }];
    }
}

async function runAuxTask<T>(keys: string[], task: (g: any) => Promise<T>, fallback: T): Promise<T> {
    for (const key of keys) {
        try {
            const groq = createGroq({ apiKey: key });
            return await task(groq);
        } catch (e: any) {
            console.warn(`[CEREBRO] âš ï¸ Key ...${key.slice(-4)} fallÃ³:`, e.message);
            continue;
        }
    }
    console.error("[CEREBRO] âŒ Todas las keys fallaron en runAuxTask");
    return fallback;
}

async function classifySymptom(text: string, groq: ReturnType<typeof createGroq>): Promise<string> {
    try {
        const { text: result } = await generateText({
            model: groq('llama-3.1-8b-instant'),
            maxOutputTokens: 80,
            temperature: 0,
            prompt: `ExtraÃ© marca, modelo y sÃ­ntomas tÃ©cnicos de este texto. RespondÃ© SOLO con JSON:
{"brand":"Samsung","model":"A52","symptoms":["reinicio"]}
Texto: "${text.slice(0, 200)}"`
        });
        const json = JSON.parse(result.trim());
        return `${json.brand} ${json.model} ${json.symptoms.join(' ')}`;
    } catch {
        return text;
    }
}

async function extractDiagnosticState(
    messages: any[],
    groq: ReturnType<typeof createGroq>
): Promise<string> {
    const turns = messages.filter(m => m.role === 'user' || m.role === 'assistant');
    if (turns.length < 3) return '';

    try {
        const conversationText = turns
            .slice(-6)
            .map(m => {
                let text = '';
                if (typeof m.content === 'string') text = m.content;
                else if (Array.isArray(m.parts)) text = m.parts.filter((p: any) => p.type === 'text').map((p: any) => p.text).join(' ');
                return `[${m.role.toUpperCase()}]: ${text.slice(0, 500)}`;
            })
            .join('\n');

        const { text: result } = await generateText({
            model: groq(DIAG_EXTRACT_MODEL),
            maxOutputTokens: 350,
            temperature: 0,
            prompt: `AnalizÃ¡ esta conversaciÃ³n y respondÃ© SOLO con JSON.
${conversationText}
JSON: {
  "device":"equipo",
  "symptoms":["sÃ­ntoma1"],
  "checked":["medido"],
  "ruledOut":["descartado"],
  "suspected":"componente",
  "learningHistory": [
    {"level": "Nivel 1", "concept": "Concepto", "measurement": "MediciÃ³n"}
  ]
}`
        });

        const diag = JSON.parse(result.trim());
        let diagString = `
### ğŸ•µï¸ ESTADO DEL DIAGNÃ“STICO:
- **Dispositivo**: ${diag.device || 'Desconocido'}
- **SÃ­ntomas**: ${diag.symptoms.join(', ')}
- **Verificado**: ${diag.checked.join(', ') || 'Nada aÃºn'}
- **Sospecha**: ${diag.suspected || 'No determinada'}`;

        if (diag.learningHistory && diag.learningHistory.length > 0) {
            diagString += `\n\n### ğŸ“ HISTORIAL DE APRENDIZAJE:
| Nivel | Concepto Aprendido | MediciÃ³n Realizada |
|-------|-------------------|-------------------|
${diag.learningHistory.map((h: any) => `| ${h.level} | ${h.concept} | ${h.measurement} |`).join('\n')}`;
        }

        return diagString;
    } catch {
        return '';
    }
}

function createFallbackModel(configs: any[], onSelect: (info: any) => void) {
    if (configs.length === 0) throw new Error("No model configs provided");
    return {
        specificationVersion: 'v2',
        provider: 'cerebro-fallback',
        modelId: 'fallback-logic',
        doGenerate: async (params: any) => {
            let lastErr;
            for (const config of configs) {
                try {
                    onSelect(config);
                    const result = await config.instance.doGenerate(params);
                    // Acomodamos finishReason si viene como objeto (falla Zod en el cliente)
                    if (result.finishReason && typeof result.finishReason === 'object') {
                        result.finishReason = (result.finishReason as any).unified || 'stop';
                    }
                    return result;
                } catch (e) {
                    lastErr = e;
                    continue;
                }
            }
            throw lastErr;
        },
        doStream: async (params: any) => {
            let lastErr;
            for (const config of configs) {
                try {
                    onSelect(config);
                    const result = await config.instance.doStream(params);

                    // Transformamos el stream para aplanar finishReason en pedazos tipo 'finish'
                    const originalStream = result.stream;
                    const transformedStream = new ReadableStream({
                        async start(controller) {
                            const reader = originalStream.getReader();
                            try {
                                while (true) {
                                    const { done, value } = await reader.read();
                                    if (done) break;

                                    // Interceptamos el mensaje de finalizaciÃ³n
                                    if (value.type === 'finish' && value.finishReason && typeof value.finishReason === 'object') {
                                        value.finishReason = value.finishReason.unified || 'stop';
                                    }
                                    controller.enqueue(value);
                                }
                            } finally {
                                reader.releaseLock();
                                controller.close();
                            }
                        }
                    });

                    return { ...result, stream: transformedStream };
                } catch (e) {
                    lastErr = e;
                    continue;
                }
            }
            throw lastErr;
        }
    };
}

function detectMode(msgLower: string, guidedMode: boolean): string {
    const ACADEMY_KEYWORDS = ['como mido', 'explicame', 'que es', 'no entiendo'];
    const EXPERT_KEYWORDS = ['reemplazo', 'reballing', 'jumper', 'rail', 'vbus'];
    const tieneDatos = (/\d+(mv|v|ohm|ma)/i).test(msgLower);

    if (guidedMode) return 'MENTOR';
    if (ACADEMY_KEYWORDS.some(k => msgLower.includes(k))) return 'ACADEMY';
    if (!tieneDatos && !EXPERT_KEYWORDS.some(k => msgLower.includes(k))) return 'ACADEMY';
    return 'STANDARD';
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// HANDLER PRINCIPAL
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export async function POST(req: NextRequest) {
    console.log("[CEREBRO] ğŸ“¥ Incoming request...");
    try {
        const keys = getGroqKeys();

        if (keys.length === 0) {
            console.error("[CEREBRO] âŒ No Groq keys found.");
            return new Response(JSON.stringify({ error: "No hay llaves de API" }), { status: 500 });
        }

        const body = await req.json() as CerebroRequestBody;
        const messages = body.messages || [];
        const guidedMode = body.guidedMode === true;
        if (!messages.length) return new Response("No messages", { status: 400 });

        const lastUserMsg = messages.findLast((m: any) => m.role === 'user');
        const images = lastUserMsg ? extractImages(lastUserMsg) : [];
        const hasImages = images.length > 0;

        let lastUserTextContent = lastUserText(lastUserMsg);
        const msgLower = lastUserTextContent.toLowerCase();

        const mode = detectMode(msgLower, guidedMode);
        let activeBasePrompt = `## ğŸ”€ MODO ACTIVO: [STANDARD]\n\n${STANDARD_PROMPT}`;
        if (mode === 'MENTOR') {
            activeBasePrompt = `## ğŸ”€ MODO ACTIVO: [GUIADO]\n\n${MENTOR_PROMPT}`;
        } else if (mode === 'ACADEMY') {
            activeBasePrompt = `## ğŸ”€ MODO ACTIVO: [ACADEMIA]\n\n${ACADEMY_PROMPT}`;
            console.log("[CEREBRO] ğŸ“ Activando MODO ACADEMIA");
        } else {
            console.log("[CEREBRO] ğŸ› ï¸ Activando MODO STANDARD");
        }

        console.log(`[CEREBRO] ğŸ” Processsing with guidedMode: ${guidedMode}`);

        let finalSystemPrompt = activeBasePrompt;

        const classifyPromise = lastUserTextContent.length > 8
            ? withTimeout(runAuxTask(keys, (g) => classifySymptom(lastUserTextContent.slice(0, 3000), g), lastUserTextContent), TIMEOUTS.classify, lastUserTextContent)
            : Promise.resolve(lastUserTextContent);

        const classifyResultValue = await classifyPromise;
        const classifiedQuery = classifyResultValue || lastUserTextContent;

        const [schemResult, ragResult, diagResult] = await Promise.allSettled([
            withTimeout(findSchematic(lastUserTextContent), TIMEOUTS.schematic, null),
            withTimeout(findSimilarRepairs(classifiedQuery), TIMEOUTS.rag, []),
            withTimeout(runAuxTask(keys, (g) => extractDiagnosticState(messages, g), ''), TIMEOUTS.diagnostic, ''),
        ]);

        // Inyectar contexto RAG (Reparaciones Similares)
        const ragMatches = ragResult.status === 'fulfilled' ? ragResult.value : [];
        console.log(`[CEREBRO] ğŸ“š RAG Matches encontrados: ${ragMatches.length}`);
        if (ragMatches.length > 0) {
            finalSystemPrompt += formatRAGContext(ragMatches);
        }

        const schematicMatch = schemResult.status === 'fulfilled' ? schemResult.value : null;
        if (schematicMatch) finalSystemPrompt += formatSchematicContext(schematicMatch, lastUserTextContent);
        const diagBlock = diagResult.status === 'fulfilled' ? diagResult.value : '';
        if (diagBlock) finalSystemPrompt += diagBlock;

        if (activeBasePrompt === MENTOR_PROMPT) {
            finalSystemPrompt += `\n\n### ğŸ”¬ MODO DIAGNÃ“STICO GUIADO ACTIVO\nHacÃ© UNA SOLA pregunta especÃ­fica.`;
        }

        finalSystemPrompt += FINAL_DIRECTIVE;

        const coreMessages = await toCoreMsgs(messages);

        if (hasImages) {
            console.log("[CEREBRO] ğŸ‘ï¸ Activando flujo VISIÃ“N");
            const visionMessages = await buildVisionMessages(coreMessages, images);
            const visionGroq = createGroq({ apiKey: keys[0] });
            const result = await streamText({
                model: visionGroq(VISION_MODEL.id) as any,
                messages: visionMessages,
                system: finalSystemPrompt,
                maxOutputTokens: MAX_OUTPUT_TOKENS,
                temperature: 0.2,
            });
            return result.toUIMessageStreamResponse({
                headers: { 'X-Cerebro-Provider': VISION_MODEL.label, 'X-Cerebro-Key': keys[0].slice(-4) }
            });
        }

        const onFinishCb = ({ usage }: any) => {
            console.log("[CEREBRO] âœ¨ Stream finish. Usage:", usage);
            if (usage?.totalTokens) {
                trackTokens(usage.totalTokens).catch(err => console.error("[CEREBRO] Background track error:", err));
            }
        };

        // ConfiguraciÃ³n de modelos
        const textModelsConfig: any[] = [];

        // Modelo principal
        for (const key of keys) {
            textModelsConfig.push({
                instance: createGroq({ apiKey: key })(TEXT_MODELS[0].id),
                label: TEXT_MODELS[0].label,
                keyId: key.slice(-4)
            });
        }

        // Fallback al modelo secundario
        for (const key of keys) {
            textModelsConfig.push({
                instance: createGroq({ apiKey: key })(TEXT_MODELS[1].id),
                label: TEXT_MODELS[1].label,
                keyId: key.slice(-4)
            });
        }

        let usedLabel = 'Unknown';
        let usedKey = '';
        const cerebroTextModel = createFallbackModel(textModelsConfig, (info) => {
            usedLabel = info.label;
            usedKey = info.keyId;
        });

        console.log("[CEREBRO] ğŸš€ Streaming response...");
        const result = await streamText({
            model: cerebroTextModel as any,
            system: finalSystemPrompt,
            messages: coreMessages,
            maxOutputTokens: MAX_OUTPUT_TOKENS,
            temperature: 0.2,
            onFinish: onFinishCb,
            maxRetries: 0,
        });

        console.log("[CEREBRO] âœ… Returning stream response headers.");
        return result.toUIMessageStreamResponse({
            headers: { 'X-Cerebro-Provider': usedLabel, 'X-Cerebro-Key': usedKey }
        });

    } catch (error: any) {
        console.error("[CEREBRO] âŒ ERROR FATAL:", error);
        return new Response(JSON.stringify({ error: error.message }), {
            status: 500,
            headers: { 'Content-Type': 'application/json' }
        });
    }
}
