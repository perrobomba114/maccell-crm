import { NextRequest } from "next/server";
import { createGroq } from "@ai-sdk/groq";
import { streamText, generateText } from "ai";
import { db as prisma } from "@/lib/db";
import { trackTokens } from "@/lib/cerebro-token-tracker";
import { findSimilarRepairs, formatRAGContext } from "@/lib/cerebro-rag";
import { findSchematic, formatSchematicContext } from "@/lib/cerebro-schematics";
import pdfParse from "pdf-parse";


// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// CONFIGURACIÃ“N
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const MAX_HISTORY_MSGS = 2; // Reducido drÃ¡sticamente para ahorrar tokens en Tier 1
const MAX_MSG_CHARS = 800;
const MAX_OUTPUT_TOKENS = 800;
const MAX_PDF_CHARS = 8000; // Ajustado a 8k para garantizar compatibilidad con Tier 1 (TPM 6k) en cascada 8B
const MAX_IMAGES = 4; // Groq max 5, usamos 4 por seguridad

export const maxDuration = 60;
export const dynamic = 'force-dynamic';

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// MODELOS
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const TEXT_MODELS = [
    { label: 'Llama 3.3 70B', id: 'llama-3.3-70b-versatile' },
    { label: 'Llama 3.1 8B', id: 'llama-3.1-8b-instant' },
];
const VISION_MODEL = { label: 'Llama 4 Scout Vision', id: 'meta-llama/llama-4-scout-17b-16e-instruct' };
const DIAG_EXTRACT_MODEL = 'llama-3.1-8b-instant'; // Fase 2: extractor de estado

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// SYSTEM PROMPTS (MODO DUAL)
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const MENTOR_PROMPT = `ActuÃ¡ como un Mentor Maestro de MACCELL. Tu objetivo es que el tÃ©cnico aprenda a diagnosticar. 

### ğŸ“œ REGLAS DE ORO DEL MENTOR:
1. **PROHIBIDO DAR EL DIAGNÃ“STICO COMPLETO:** No des soluciones ni porcentajes de entrada. Solo analizÃ¡ el sÃ­ntoma y pedÃ­ UNA (1) mediciÃ³n.
2. **PEDÃ VALORES CON REFERENCIA:** Cuando pidas medir algo, decÃ­ quÃ© valor debe encontrar: "MedÃ­ caÃ­da de tensiÃ³n en el Pin X; el valor normal es .450v". 
3. **TONO EDUCATIVO:** Si pedÃ­s medir una bobina, explicÃ¡ brevemente quÃ© funciÃ³n cumple (ej: "L5001 es la bobina de switching del booster").
4. **NO SUGERIR REBALLING:** Salvo que todas las mediciones perifÃ©ricas (diodos, capacitores, voltajes) den mal.
5. **PRECISIÃ“N TÃ‰CNICA:** UsÃ¡ los nombres del manual (L500, U500).

### ğŸ› ï¸ ESTRUCTURA DE RESPUESTA MENTOR:
- **AnÃ¡lisis Breve:** "Este sÃ­ntoma suele estar en la lÃ­nea de Ãnodo o en el driver de backlight..."
- **La MediciÃ³n del Momento:** PedÃ­ UNA sola prueba puntual y esperÃ¡ respuesta.
- **Valor de Referencia:** Decile quÃ© nÃºmero esperar.`;

const STANDARD_PROMPT = `ActuÃ¡ como un Asistente TÃ©cnico Experto de MACCELL. 
Tu misiÃ³n es dar un informe de diagnÃ³stico directo y resolutivo.

### ESTRUCTURA OBLIGATORIA:
1. **AnÃ¡lisis Diferencial ğŸ“Š** â€” HipÃ³tesis con % estimado.
2. **ğŸ” ESTADO DEL SISTEMA** â€” ICs y lÃ­neas involucradas.
3. **ğŸ•µï¸â€â™‚ï¸ PROTOCOLO DE MEDICIÃ“N** â€” Lista de todas las pruebas a realizar con sus valores.
4. **ğŸ¯ INTERVENCIÃ“N SUGERIDA** â€” IC a cambiar o tÃ©cnica a aplicar.

### REGLA DE ORO:
- PriorizÃ¡ siempre las "Soluciones Verificadas" del taller.`;

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// UTILIDADES
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function truncate(text: string, max = MAX_MSG_CHARS): string {
    if (!text) return "";
    return text.length <= max ? text : text.slice(0, max) + '...';
}

async function extractPdfText(dataUrl: string): Promise<string | null> {
    try {
        const base64 = dataUrl.split(',')[1];
        if (!base64) return null;
        const buffer = Buffer.from(base64, 'base64');
        const parsed = await pdfParse(buffer);
        const text = parsed.text?.trim();
        if (!text) return null;
        return text.length > MAX_PDF_CHARS
            ? text.slice(0, MAX_PDF_CHARS) + '\n[...schematic truncado...]'
            : text;
    } catch (err: any) {
        console.warn('[CEREBRO] âš ï¸ Error parseando PDF:', err.message);
        return null;
    }
}

function extractImages(msg: any): string[] {
    const images: string[] = [];
    if (!msg || !Array.isArray(msg.parts)) return images;
    for (const p of msg.parts) {
        const mt = p.mediaType || p.file?.mediaType || '';
        const url = p.url || p.file?.url || '';
        if (mt.startsWith('image/') && url) images.push(url);
        if (p.type === 'image' && (p.image || p.url)) images.push(p.image || p.url);
    }
    return images.slice(0, MAX_IMAGES);
}

async function buildVisionMessages(messages: any[], images: string[]): Promise<any[]> {
    const lastMsg = messages[messages.length - 1];
    const history = messages.slice(0, -1).slice(-MAX_HISTORY_MSGS + 1);
    const result: any[] = [];

    for (const m of history) {
        if (m.role !== 'user' && m.role !== 'assistant') continue;
        let text = '';
        if (Array.isArray(m.parts)) {
            text = m.parts.filter((p: any) => p.type === 'text').map((p: any) => p.text || '').join(' ');
        } else if (typeof m.content === 'string') {
            text = m.content;
        }
        result.push({ role: m.role, content: truncate(text.trim()) || '[mensaje vacÃ­o]' });
    }

    let userText = '';
    if (Array.isArray(lastMsg.parts)) {
        userText = lastMsg.parts.filter((p: any) => p.type === 'text').map((p: any) => p.text || '').join(' ');
    } else if (typeof lastMsg.content === 'string') {
        userText = lastMsg.content;
    }

    const contentParts: any[] = [
        { type: 'text', text: truncate(userText.trim()) || 'Â¿PodÃ©s analizar esta imagen de placa?' }
    ];
    for (const imgUrl of images) {
        contentParts.push({ type: 'image', image: imgUrl });
    }

    result.push({ role: 'user', content: contentParts });
    return result;
}

async function toCoreMsgs(messages: any[]): Promise<any[]> {
    try {
        const lastMsg = messages[messages.length - 1];
        const history = messages.slice(0, -1).slice(-MAX_HISTORY_MSGS + 1);
        const result: any[] = [];

        for (const m of history) {
            if (m.role !== 'user' && m.role !== 'assistant') continue;
            let textContent = '';
            if (Array.isArray(m.parts)) {
                for (const p of m.parts) {
                    if (p.type === 'text' && p.text) textContent += p.text + ' ';
                    if (p.type === 'file') {
                        const mt = p.mediaType || p.file?.mediaType || '';
                        const url = p.url || p.file?.url || '';
                        if (mt === 'application/pdf' && url) {
                            const pdf = await extractPdfText(url);
                            if (pdf) textContent += `\n\nğŸ“„ [PDF ADJUNTO EN HISTORIAL]:\n${pdf}\n`;
                        }
                    }
                }
            }
            if (typeof m.content === 'string' && m.content.trim()) textContent = m.content;
            if (Array.isArray(m.content)) {
                textContent = m.content.filter((c: any) => c.type === 'text').map((c: any) => c.text).join(' ');
            }
            const finalText = truncate(textContent.trim());
            result.push({ role: m.role, content: finalText || '[mensaje vacÃ­o]' });
        }

        {
            const m = lastMsg;
            if (m.role === 'user' || m.role === 'assistant') {
                let textContent = '';
                const pdfTexts: string[] = [];
                if (Array.isArray(m.parts)) {
                    for (const p of m.parts) {
                        if (p.type === 'text' && p.text) textContent += p.text + ' ';
                        if (p.type === 'file') {
                            const mt = p.mediaType || p.file?.mediaType || '';
                            const url = p.url || p.file?.url || '';
                            if (mt === 'application/pdf' && url) {
                                const pdf = await extractPdfText(url);
                                if (pdf) pdfTexts.push(pdf);
                            }
                        }
                    }
                }
                if (typeof m.content === 'string' && m.content.trim()) textContent = m.content;
                if (Array.isArray(m.content)) {
                    textContent = m.content.filter((c: any) => c.type === 'text').map((c: any) => c.text).join(' ');
                }
                textContent = truncate(textContent.trim());
                if (pdfTexts.length > 0) {
                    const pdfBlock = pdfTexts.map((t, i) => `\n\nğŸ“„ [SCHEMATIC/PDF #${i + 1}]:\n${t}`).join('\n');
                    textContent = textContent + pdfBlock;
                }
                result.push({ role: m.role, content: textContent || '[mensaje vacÃ­o]' });
            }
        }
        return result;
    } catch (e) {
        console.error("[CEREBRO] toCoreMsgs error:", e);
        return [{ role: 'user', content: 'Error procesando mensajes' }];
    }
}

async function withTimeout<T>(promise: Promise<T>, ms: number, fallback: T): Promise<T> {
    return Promise.race([
        promise,
        new Promise<T>((resolve) => setTimeout(() => resolve(fallback), ms))
    ]);
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// FASE 1.3 â€” Clasificador de sÃ­ntomas previo a RAG
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
/**
 * Extrae marca, modelo y sÃ­ntomas del mensaje del tÃ©cnico con llama-3.1-8b.
 * Retorna una query enriquecida para el RAG, mÃ¡s precisa que el texto crudo.
 * Ejemplo: "galaxy a52 se queda colgado" â†’ "Samsung A52 reinicio freezing"
 */
async function classifySymptom(
    text: string,
    groq: ReturnType<typeof createGroq>
): Promise<string> {
    if (text.length < 8) return text;
    try {
        const { text: result } = await generateText({
            model: groq(DIAG_EXTRACT_MODEL),
            temperature: 0,
            maxOutputTokens: 80,
            prompt: `ExtraÃ© marca, modelo y sÃ­ntomas tÃ©cnicos de este texto. RespondÃ© SOLO con JSON, sin markdown:
{"brand":"Samsung","model":"A52","symptoms":["reinicio","no carga"]}
Si no hay info, usÃ¡ vacÃ­os.

Texto: "${text.slice(0, 200)}"`
        });
        const match = result.match(/\{[\s\S]*\}/);
        if (!match) return text;
        const c = JSON.parse(match[0]);
        const parts = [c.brand, c.model, ...(c.symptoms || [])].filter(Boolean);
        if (parts.length === 0) return text;
        const enriched = parts.join(' ');
        console.log(`[CEREBRO] ğŸ·ï¸ SÃ­ntoma clasificado: "${enriched}"`);
        return enriched;
    } catch {
        return text; // fallback al texto original
    }
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// FASE 2 â€” Extractor de estado de diagnÃ³stico
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
/**
 * Analiza el historial de conversaciÃ³n con llama-3.1-8b (rÃ¡pido) y extrae
 * en JSON quÃ© se midiÃ³, quÃ© se descartÃ³ y cuÃ¡l es la sospecha actual.
 * El resultado se inyecta en el system prompt del modelo 70B para que
 * NO repita mediciones ya realizadas por el tÃ©cnico.
 * Solo se activa desde el 3er turno de la conversaciÃ³n.
 */
async function extractDiagnosticState(
    messages: any[],
    groq: ReturnType<typeof createGroq>
): Promise<string> {
    const turns = messages.filter(m => m.role === 'user' || m.role === 'assistant');
    if (turns.length < 3) return ''; // Sin historial Ãºtil todavÃ­a

    try {
        const conversationText = turns
            .slice(-6)
            .map(m => {
                let text = '';
                if (typeof m.content === 'string') text = m.content;
                else if (Array.isArray(m.parts)) {
                    // Solo tomamos texto, ignoramos PDF pesado para no saturar tokens en esta fase
                    text = m.parts.filter((p: any) => p.type === 'text').map((p: any) => p.text || '').join(' ');
                }
                // Limpiamos menciones de PDF previo para que el extractor no se confunda
                text = text.replace(/ğŸ“„ \[PDF ADJUNTO[\s\S]*?\n/g, '');
                return `[${m.role.toUpperCase()}]: ${text.slice(0, 500)}`;
            })
            .join('\n');

        const { text } = await generateText({
            model: groq(DIAG_EXTRACT_MODEL),
            temperature: 0,
            maxOutputTokens: 300,
            prompt: `Eres un asistente tÃ©cnico de electrÃ³nica. AnalizÃ¡ esta conversaciÃ³n y respondÃ© SOLO con un JSON (sin markdown).

CONVERSACIÃ“N:
${conversationText}

JSON requerido:
{"device":"equipo o vacÃ­o","symptoms":["sÃ­ntoma1"],"checked":["ya medido/verificado"],"ruledOut":["descartado"],"suspected":"componente o vacÃ­o"}`
        });

        const jsonMatch = text.match(/\{[\s\S]*\}/);
        if (!jsonMatch) return '';
        const state = JSON.parse(jsonMatch[0]);

        const hasInfo = (state.checked?.length > 0) || (state.ruledOut?.length > 0) || state.suspected;
        if (!hasInfo) return '';

        const lines: string[] = [];
        if (state.device) lines.push(`Equipo: ${state.device}`);
        if (state.symptoms?.length) lines.push(`SÃ­ntomas: ${state.symptoms.join(', ')}`);
        if (state.checked?.length) lines.push(`Ya verificado: ${state.checked.join(' Â· ')}`);
        if (state.ruledOut?.length) lines.push(`Descartado: ${state.ruledOut.join(', ')}`);
        if (state.suspected) lines.push(`Sospecha actual: ${state.suspected}`);

        console.log('[CEREBRO] ğŸ§ª Estado diagnÃ³stico:', JSON.stringify(state));
        return `\n\n### ğŸ§ª ESTADO DEL DIAGNÃ“STICO (NO REPETIR)\n${lines.join('\n')}\nâš ï¸ NO repitas mediciones ya realizadas. ContinuÃ¡ desde donde quedÃ³ el tÃ©cnico.`;
    } catch (err: any) {
        console.warn('[CEREBRO] âš ï¸ extractDiagnosticState fallÃ³:', err.message?.slice(0, 80));
        return '';
    }
}

// Helper para tareas auxiliares (classify, extract) que prueba todas las llaves
async function runAuxTask<T>(
    keys: string[],
    task: (groq: ReturnType<typeof createGroq>) => Promise<T>,
    fallback: T
): Promise<T> {
    for (const key of keys) {
        try {
            const groq = createGroq({ apiKey: key });
            return await task(groq);
        } catch (err: any) {
            console.warn(`[CEREBRO] Tarea auxiliar fallÃ³ con llave ${key.slice(-4)}: ${err.message}`);
        }
    }
    return fallback;
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// HANDLER
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function createFallbackModel(
    models: { instance: any; label: string; keyId: string }[],
    successCallback: (info: { label: string; keyId: string }) => void
): any {
    return {
        specificationVersion: "v3",
        provider: "cerebro-fallback",
        modelId: "cerebro-fallback",
        defaultObjectGenerationMode: models[0]?.instance.defaultObjectGenerationMode,
        defaultTextGenerationMode: models[0]?.instance.defaultTextGenerationMode, // just in case
        async doGenerate(options: any) {
            let lastError: any;
            for (const { instance, label, keyId } of models) {
                try {
                    const result = await instance.doGenerate(options);
                    successCallback({ label, keyId });
                    return result;
                } catch (err: any) {
                    lastError = err;
                    console.warn(`[CEREBRO] âš ï¸ Fallback en doGenerate (${label}):`, err?.message?.slice(0, 150) || err);
                }
            }
            throw lastError;
        },
        async doStream(options: any) {
            let lastError: any;
            for (const [i, { instance, label, keyId }] of models.entries()) {
                try {
                    const result = await instance.doStream(options);
                    console.log(`[CEREBRO] âœ… Provider aceptado en intento ${i + 1} (${label})`);
                    successCallback({ label, keyId });
                    return result;
                } catch (err: any) {
                    lastError = err;
                    console.warn(`[CEREBRO] âš ï¸ Provider rechazado en intento ${i + 1} (${label} ${keyId}):`, err?.message?.slice(0, 150) || err);
                }
            }
            console.error(`[CEREBRO] âŒ Todos los providers fallaron.`);
            throw lastError;
        }
    };
}

export async function POST(req: NextRequest) {
    console.log("[CEREBRO] ğŸš€ PeticiÃ³n iniciada");

    try {
        const keys = [
            process.env.GROQ_API_KEY,
            process.env.GROQ_API_KEY_2,
            process.env.GROQ_API_KEY_3
        ].filter((k): k is string => !!k && k.length > 10);

        if (keys.length === 0) {
            return new Response("Error: No hay llaves de API de Groq configuradas.", { status: 500 });
        }

        const body = await req.json();
        const messages = body.messages || [];
        const guidedMode = body.guidedMode === true;
        if (!messages.length) return new Response("No messages provided", { status: 400 });

        // No creamos un groqAux fijo, usaremos runAuxTask

        // â”€â”€ Detectar imÃ¡genes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        const lastUserMsg = messages.findLast((m: any) => m.role === 'user');
        const images = lastUserMsg ? extractImages(lastUserMsg) : [];
        const hasImages = images.length > 0;
        console.log(`[CEREBRO] ğŸ“¸ ImÃ¡genes: ${images.length} | Modo: ${hasImages ? 'VISION' : 'TEXT'}`);

        // â”€â”€ Extraer texto del usuario para RAG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        let lastUserText = '';
        if (lastUserMsg) {
            if (typeof lastUserMsg.content === 'string') {
                lastUserText = lastUserMsg.content;
            } else if (Array.isArray(lastUserMsg.parts)) {
                lastUserText = lastUserMsg.parts
                    .filter((p: any) => p.type === 'text')
                    .map((p: any) => p.text || '')
                    .join(' ');
            }
        }

        // â”€â”€ SelecciÃ³n de Prompt Base (Modo Dual) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        // Prioridad: 1. Palabra clave en el mensaje, 2. Flag del body, 3. Standard por defecto
        let activeBasePrompt = STANDARD_PROMPT;
        const msgLower = lastUserText.toLowerCase();

        if (msgLower.includes('modo guiado') || msgLower.includes('con modo guiado') || guidedMode) {
            activeBasePrompt = MENTOR_PROMPT;
        } else if (msgLower.includes('sin modo guiado') || msgLower.includes('modo estandar')) {
            activeBasePrompt = STANDARD_PROMPT;
        }

        let finalSystemPrompt = activeBasePrompt;

        const [classifyResult, ragDirectResult, schemResult, diagResult] = await Promise.allSettled([
            // Fase 1.3: clasificar sÃ­ntoma
            lastUserText.length > 8
                ? withTimeout(runAuxTask(keys, (g: ReturnType<typeof createGroq>) => classifySymptom(lastUserText.slice(0, 3000), g), lastUserText), 2500, lastUserText)
                : Promise.resolve(lastUserText),
            // RAG directo
            lastUserText.length > 3
                ? withTimeout(findSimilarRepairs(lastUserText, 1, 0.6), 4000, [])
                : Promise.resolve([]),
            // Fase 4: schematic auto-lookup
            withTimeout(findSchematic(lastUserText), 3000, null),
            // Fase 2: estado del diagnÃ³stico
            withTimeout(runAuxTask(keys, (g: ReturnType<typeof createGroq>) => extractDiagnosticState(messages, g), ''), 5000, ''),
        ]);

        let similar = ragDirectResult.status === 'fulfilled' ? ragDirectResult.value : [];
        const classifiedQuery = classifyResult.status === 'fulfilled' ? classifyResult.value : lastUserText;

        // Si RAG directo no encontrÃ³ nada Y classify generÃ³ una query mejor â†’ 2do intento
        if (similar.length === 0 && classifiedQuery !== lastUserText && classifiedQuery.length > 3) {
            const ragFallback = await withTimeout(findSimilarRepairs(classifiedQuery, 1, 0.6), 3000, []);
            if (ragFallback.length > 0) {
                similar = ragFallback;
                console.log(`[CEREBRO] ğŸ·ï¸ RAG mejorado por classify: ${similar.length} casos`);
            }
        }

        if (similar.length > 0) {
            finalSystemPrompt += formatRAGContext(similar);
            console.log(`[CEREBRO] ğŸ§  RAG: ${similar.length} casos`);
        }

        const diagBlock = diagResult.status === 'fulfilled' ? diagResult.value : '';
        if (diagBlock) finalSystemPrompt += diagBlock;

        const schematic = schemResult.status === 'fulfilled' ? schemResult.value : null;
        if (schematic) {
            finalSystemPrompt += formatSchematicContext(schematic);
            console.log(`[CEREBRO] ğŸ“‹ Schematic auto-inyectado: ${schematic.brand} ${schematic.model}`);
        }

        // Fase 5: Modo DiagnÃ³stico Guiado
        if (activeBasePrompt === MENTOR_PROMPT) {
            finalSystemPrompt += `

### ğŸ”¬ MODO DIAGNÃ“STICO GUIADO ACTIVO
REGLA CRÃTICA: HacÃ© UNA SOLA pregunta especÃ­fica por turno.
NO des el diagnÃ³stico completo junto. EsperÃ¡ la respuesta del tÃ©cnico antes de continuar.
Ejemplo correcto:
  Turno 1: "ConectÃ¡ alimentaciÃ³n externa. Â¿CuÃ¡nto mA drena?"
  Turno 2: (tÃ©cnico responde 350mA) â†’ "Corto confirmado. MedÃ­ con cÃ¡mara tÃ©rmica la zona del PMIC. Â¿EncontrÃ¡s algo caliente?"
SeguÃ­ este flujo hasta identificar el componente exacto.`;
            console.log('[CEREBRO] ğŸ”¬ Modo Guiado activo');
        }

        // â”€â”€ Ticket lookup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        const ticketMatch = lastUserText.match(/MAC\d*-\d+/gi);
        if (ticketMatch) {
            const repair = await withTimeout(
                prisma.repair.findUnique({ where: { ticketNumber: ticketMatch[0].toUpperCase() } }),
                2000,
                null
            );
            if (repair) {
                finalSystemPrompt += `\n\n### CASO TICKET ${repair.ticketNumber}:\nEquipo: ${repair.deviceBrand} ${repair.deviceModel}\nProblema: ${repair.problemDescription}`;
            }
        }

        const onFinishCb = ({ usage }: any) => {
            if (usage?.totalTokens) {
                trackTokens(usage.totalTokens);
                console.log(`[CEREBRO] ğŸª™ Tokens: ${usage.totalTokens} (in: ${usage.inputTokens}, out: ${usage.outputTokens})`);
            }
        };

        // â”€â”€ MODO VISIÃ“N â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if (hasImages) {
            console.log(`[CEREBRO] ğŸ”­ Iniciando modo VisiÃ³n...`);
            const visionModels = keys.map(key => ({
                instance: createGroq({ apiKey: key })(VISION_MODEL.id),
                label: VISION_MODEL.label,
                keyId: key.slice(-4)
            }));

            let usedLabel = VISION_MODEL.label;
            let usedKey = '';

            const cerebroVisionModel = createFallbackModel(visionModels, (info) => {
                usedLabel = info.label;
                usedKey = info.keyId;
            });

            try {
                const visionMessages = await buildVisionMessages(messages, images);
                const result = await streamText({
                    model: cerebroVisionModel as any,
                    system: finalSystemPrompt,
                    messages: visionMessages,
                    maxOutputTokens: MAX_OUTPUT_TOKENS,
                    temperature: 0.2,
                    onFinish: onFinishCb,
                    maxRetries: 0,
                });
                return result.toUIMessageStreamResponse({
                    headers: {
                        'Cache-Control': 'no-cache, no-store, must-revalidate',
                        'X-Cerebro-Provider': usedLabel,
                        'X-Cerebro-Key': usedKey
                    }
                });
            } catch (visionErr: any) {
                console.warn(`[CEREBRO] âš ï¸ Vision mode fallback cascade failed:`, visionErr.message);
            }
        }

        // â”€â”€ MODO TEXTO â€” cascada 70B â†’ 8B â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        const coreMessages = await toCoreMsgs(messages);
        console.log(`[CEREBRO] ğŸ“¨ Mensajes: ${coreMessages.length} | Prompt length: ${finalSystemPrompt.length}`);

        const textModelsConfig = [];
        for (const m of TEXT_MODELS) {
            for (const key of keys) {
                textModelsConfig.push({
                    instance: createGroq({ apiKey: key })(m.id),
                    label: m.label,
                    keyId: key.slice(-4)
                });
            }
        }

        let usedLabel = 'Unknown';
        let usedKey = '';

        const cerebroTextModel = createFallbackModel(textModelsConfig, (info) => {
            usedLabel = info.label;
            usedKey = info.keyId;
        });

        try {
            const result = await streamText({
                model: cerebroTextModel as any,
                system: finalSystemPrompt,
                messages: coreMessages,
                maxOutputTokens: MAX_OUTPUT_TOKENS,
                temperature: 0.2,
                onFinish: onFinishCb,
                maxRetries: 0,
            });
            return result.toUIMessageStreamResponse({
                headers: {
                    'Cache-Control': 'no-cache, no-store, must-revalidate',
                    'X-Cerebro-Provider': usedLabel,
                    'X-Cerebro-Key': usedKey
                }
            });
        } catch (err: any) {
            console.warn(`[CEREBRO] âš ï¸ Text mode fallback cascade failed:`, err.message);
        }

        return new Response("Todos los modelos Groq fallaron.", { status: 503 });

    } catch (error: any) {
        console.error("[CEREBRO] âŒ ERROR FATAL:", error);
        return new Response(`Cerebro Offline: ${error.message}`, { status: 500 });
    }
}
