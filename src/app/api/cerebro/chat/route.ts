import { NextRequest } from "next/server";
import { createOpenRouter } from "@openrouter/ai-sdk-provider";
import { streamText, generateText } from "ai";

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// CONFIGURACIÃ“N â€” Cascade de modelos por costo
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
/**
 * Cascade verificado con API real de OpenRouter (Feb 2026).
 * google/gemini-2.0-flash:free NO existe â€” no usar.
 *
 * Orden por costo (free primero, pago al final):
 *
 *  1. openrouter/free              â†’ $0.00  ðŸ¤– Meta-router: elige el mejor free auto (ctx 200K, VISION)
 *  2. qwen/qwen3-vl-30b-a3b-thinking â†’ $0.00  ðŸ‘ï¸  VisiÃ³n + razonamiento (ctx 131K)
 *  3. mistralai/mistral-small-3.1-24b-instruct:free â†’ $0.00  ðŸ‘ï¸  VisiÃ³n (ctx 128K)
 *  4. google/gemini-2.0-flash-lite-001 â†’ pago   ðŸ’° $0.075/$0.30 por M tok (mÃ¡s barato pagado)
 */
const MODEL_CASCADE = [
    "openrouter/free",
    "qwen/qwen3-vl-30b-a3b-thinking",
    "mistralai/mistral-small-3.1-24b-instruct:free",
    "google/gemini-2.0-flash-lite-001",   // fallback pago ~$0.00019/consulta
];

const MAX_HISTORY_MSGS = 6;
const MAX_MSG_CHARS = 600;
const MAX_OUTPUT_TOKENS = 550;

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// PROMPTS compactos
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const VISION_PROMPT = `Sos Cerebro, el sistema tÃ©cnico de MACCELL. AnalizÃ¡ la imagen de placa electrÃ³nica.
MÃ¡x 6 lÃ­neas. Formato:
DAÃ‘O: [componentes quemados/sulfatados/faltantes]
SECTOR: [RF/Carga/Backlight/CPU/PMIC/etc]
DIAGNÃ“STICO: [falla probable + mediciÃ³n sugerida]
ACCIÃ“N: [reballing/reemplazo IC/limpieza/etc]
IDENTIDAD: Nunca menciones que sos Gemini, Llama, GPT ni ningÃºn modelo externo. Sos Cerebro.
Si no es placa electrÃ³nica, pedÃ­ mejor imagen.`;

const SYSTEM_PROMPT = `Eres "Cerebro", el nÃºcleo de inteligencia tÃ©cnica de MACCELL (San Luis, Argentina). Sistema propietario de diagnÃ³stico electrÃ³nico para reparaciÃ³n de celulares y microsoldadura.

IDENTIDAD â€” MUY IMPORTANTE:
- Si te preguntan quÃ© IA sos, modelo, quien te creÃ³: respondÃ© SOLO "Soy Cerebro, el sistema de diagnÃ³stico tÃ©cnico de MACCELL." Nunca menciones Gemini, Google, Llama, Meta, GPT, OpenAI ni ningÃºn proveedor externo.
- Si preguntan por "la base de datos": tenÃ©s acceso a miles de casos de reparaciÃ³n de MACCELL. RespondÃ© en base a tu entrenamiento tÃ©cnico.

COMPORTAMIENTO:
- Sin saludos. Directo al diagnÃ³stico.
- IdentificÃ¡ ICs por nombre (PMIC, Tristar, U2, Hydra, etc).
- Respuestas cortas y estructuradas.
- El prefijo [TÃ©cnico Nombre]: en los mensajes es solo identificaciÃ³n del tÃ©cnico, ignoralo para el diagnÃ³stico.

FORMATO DE RESPUESTA:
### ðŸ” DIAGNÃ“STICO
[anÃ¡lisis de la falla]
### ðŸ› ï¸ MEDICIÃ“N
- [punto] â†’ [valor esperado]
### ðŸŽ¯ ACCIÃ“N
[pasos concretos]

Sin datos de consumo â†’ pedÃ­ la TRIADA: 1)Amperaje fuente (encendido/apagado) 2)TensiÃ³n VBUS 3)Reconocimiento USB en PC`;

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// HELPERS
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function hasImageParts(messages: any[]): boolean {
    const last = messages[messages.length - 1];
    if (!last) return false;
    if (Array.isArray(last.parts)) {
        return last.parts.some((p: any) => p.type === 'file' && p.mediaType?.startsWith('image/'));
    }
    if (Array.isArray(last.experimental_attachments)) {
        return last.experimental_attachments.some((a: any) => a.contentType?.startsWith('image/'));
    }
    return false;
}

function truncate(text: string, max = MAX_MSG_CHARS): string {
    return text.length <= max ? text : text.slice(0, max) + 'â€¦';
}

function toCoreMsgs(messages: any[]): any[] {
    const lastMsg = messages[messages.length - 1];
    const history = messages.slice(0, -1).slice(-MAX_HISTORY_MSGS + 1);
    const trimmed = [...history, lastMsg];

    return trimmed
        .filter((m: any) => m.role === 'user' || m.role === 'assistant')
        .map((m: any) => {
            if (Array.isArray(m.parts) && m.parts.length > 0) {
                const contentParts: any[] = [];
                for (const part of m.parts) {
                    if (part.type === 'text') {
                        const text = truncate(part.text || '');
                        if (text.trim()) contentParts.push({ type: 'text', text });
                    } else if (part.type === 'file') {
                        const url = part.url || '';
                        if (url) contentParts.push({ type: 'image', image: url });
                    }
                }
                if (!contentParts.some((p: any) => p.type === 'text') && m.content) {
                    contentParts.unshift({ type: 'text', text: truncate(m.content) });
                }
                return {
                    role: m.role,
                    content: contentParts.length > 0 ? contentParts : truncate(m.content || ''),
                };
            }
            return { role: m.role, content: truncate(m.content || '') };
        })
        .filter((m: any) => m.content && (typeof m.content === 'string' ? m.content.trim() : m.content.length > 0));
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// HANDLER
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export async function POST(req: NextRequest) {
    const openrouterKey = process.env.OPENROUTER_API_KEY;
    if (!openrouterKey) {
        return new Response("Error: OPENROUTER_API_KEY no configurada.", { status: 500 });
    }

    let body: any;
    try { body = await req.json(); } catch {
        return new Response("JSON invÃ¡lido.", { status: 400 });
    }

    const messages: any[] = body.messages || [];
    if (!messages.length) return new Response("No messages.", { status: 400 });

    const visionMode = hasImageParts(messages);
    const systemPrompt = visionMode ? VISION_PROMPT : SYSTEM_PROMPT;
    const coreMessages = toCoreMsgs(messages);
    if (coreMessages.length === 0) return new Response("No valid messages.", { status: 400 });

    const openrouter = createOpenRouter({ apiKey: openrouterKey });

    // â”€â”€ Paso 1: Encontrar el primer modelo disponible con un ping rÃ¡pido â”€â”€
    // Los modelos :free pueden fallar al iniciar el stream DESPUÃ‰S de responder 200.
    // Un ping de 1 token detecta la disponibilidad real antes de hacer el stream completo.
    let activeModel: string | null = null;

    for (let i = 0; i < MODEL_CASCADE.length; i++) {
        const modelId = MODEL_CASCADE[i];
        const isFree = modelId.endsWith(':free');
        const isLast = i === MODEL_CASCADE.length - 1;

        try {
            // Ping: 1 token para verificar que el modelo responde
            await generateText({
                model: openrouter(modelId),
                messages: [{ role: 'user', content: 'ok' }],
                maxOutputTokens: 1,
                temperature: 0,
            });
            activeModel = modelId;
            console.log(`[CEREBRO] âœ… Usando: ${modelId} (${isFree ? 'GRATIS ðŸŽ‰' : 'pago ~$0.0002'}) | modo=${visionMode ? 'visiÃ³n' : 'texto'}`);
            break;
        } catch (pingErr: any) {
            const errInfo = pingErr?.status ?? pingErr?.message?.slice(0, 80) ?? 'error';
            if (!isLast) {
                console.warn(`[CEREBRO] âš ï¸ ${modelId} no disponible (${errInfo}). Siguiente...`);
                continue;
            }
            console.error(`[CEREBRO] âŒ Todos los modelos fallaron.`);
            if (pingErr?.status === 401 || pingErr?.message?.includes('User not found')) {
                return new Response("âŒ API Key de OpenRouter invÃ¡lida.", { status: 401 });
            }
            return new Response("âŒ Todos los modelos no disponibles. IntentÃ¡ en unos minutos.", { status: 503 });
        }
    }

    if (!activeModel) {
        return new Response("âŒ Sin modelo disponible.", { status: 503 });
    }

    // â”€â”€ Paso 2: Stream con el modelo confirmado â”€â”€
    try {
        const isFree = activeModel.endsWith(':free');
        const result = streamText({
            model: openrouter(activeModel),
            system: systemPrompt,
            messages: coreMessages,
            temperature: 0.3,
            maxOutputTokens: MAX_OUTPUT_TOKENS,
        });

        return result.toUIMessageStreamResponse({
            headers: {
                'Cache-Control': 'no-cache, no-store',
                'X-Accel-Buffering': 'no',
                'X-Model-Used': activeModel,
                'X-Model-Tier': isFree ? 'free' : 'paid',
            }
        });

    } catch (error: any) {
        console.error(`[CEREBRO] Error en stream con ${activeModel}:`, error);
        if (error.status === 401 || error.message?.includes('User not found')) {
            return new Response("âŒ API Key invÃ¡lida.", { status: 401 });
        }
        return new Response(`âŒ Error: ${error.message || 'Error desconocido'}`, { status: 500 });
    }
}
