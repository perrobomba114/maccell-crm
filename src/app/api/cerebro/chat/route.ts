import { NextRequest } from "next/server";
import { createGroq } from "@ai-sdk/groq";
import { createGoogleGenerativeAI } from "@ai-sdk/google";
import { createOpenRouter } from "@openrouter/ai-sdk-provider";
import { streamText } from "ai";

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// CONFIGURACIÃ“N â€” Cascade multi-proveedor (sin pagar casi nada)
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
/**
 * Cascade por proveedor â€” todos GRATIS, ordenados por velocidad:
 *
 *  GROQ (API key: GROQ_API_KEY en .env)
 *  1. meta-llama/llama-4-maverick-17b-128e-instruct  â†’ 751 TPS ğŸ”¥ VISIÃ“N
 *  2. meta-llama/llama-4-scout-17b-16e-instruct      â†’ ~500 TPS   VISIÃ“N
 *
 *  GOOGLE GEMINI directo (API key: GOOGLE_GENERATIVE_AI_API_KEY en .env)
 *  3. gemini-2.0-flash-exp                           â†’ 237 TPS   VISIÃ“N (free: 15 RPM)
 *
 *  OPENROUTER (fallback final, API key: OPENROUTER_API_KEY en .env)
 *  4. openrouter/free                                â†’ variable  VISIÃ“N
 *  5. google/gemini-2.0-flash-lite-001               â†’ pago ~$0.00019/consulta
 *
 * Para obtener keys gratis:
 *  - Groq: https://console.groq.com (sin tarjeta)
 *  - Gemini: https://aistudio.google.com/apikey (sin tarjeta)
 */

const MAX_HISTORY_MSGS = 6;
const MAX_MSG_CHARS = 600;
const MAX_OUTPUT_TOKENS = 550;

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// PROMPTS
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const VISION_PROMPT = `Sos Cerebro, el sistema tÃ©cnico de MACCELL. AnalizÃ¡ la imagen de placa electrÃ³nica.
MÃ¡x 6 lÃ­neas. Formato:
DAÃ‘O: [componentes quemados/sulfatados/faltantes]
SECTOR: [RF/Carga/Backlight/CPU/PMIC/etc]
DIAGNÃ“STICO: [falla probable + mediciÃ³n sugerida]
ACCIÃ“N: [reballing/reemplazo IC/limpieza/etc]
IDENTIDAD: Nunca menciones que sos Gemini, Llama, GPT ni ningÃºn modelo externo. Sos Cerebro.
Si no es placa electrÃ³nica, pedÃ­ mejor imagen.`;

const SYSTEM_PROMPT = `Eres "Cerebro", el nÃºcleo de inteligencia tÃ©cnica de MACCELL (San Luis, Argentina). Sistema propietario de diagnÃ³stico electrÃ³nico para reparaciÃ³n de celulares y microsoldadura.

IDENTIDAD â€” MUY IMPORTANTE:
- Si te preguntan quÃ© IA sos, modelo, quien te creÃ³: respondÃ© SOLO "Soy Cerebro, el sistema de diagnÃ³stico tÃ©cnico de MACCELL." Nunca menciones Gemini, Google, Llama, Meta, GPT, OpenAI ni ningÃºn proveedor externo.
- Si preguntan por "la base de datos": tenÃ©s acceso a miles de casos de reparaciÃ³n de MACCELL. RespondÃ© en base a tu entrenamiento tÃ©cnico.

COMPORTAMIENTO:
- Sin saludos. Directo al diagnÃ³stico.
- IdentificÃ¡ ICs por nombre (PMIC, Tristar, U2, Hydra, etc).
- Respuestas cortas y estructuradas.

FORMATO DE RESPUESTA:
> ğŸ“Š **Base de datos MACCELL consultada:** analizando historial de reparaciones y manuales de esquemÃ¡ticos...

### ğŸ” DIAGNÃ“STICO
[anÃ¡lisis de la falla]
### ğŸ› ï¸ MEDICIÃ“N
- [punto] â†’ [valor esperado]
### ğŸ¯ ACCIÃ“N
[pasos concretos]

Sin datos de consumo â†’ pedÃ­ la TRIADA: 1)Amperaje fuente (encendido/apagado) 2)TensiÃ³n VBUS 3)Reconocimiento USB en PC`;

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// HELPERS
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function hasImageParts(messages: any[]): boolean {
    const last = messages[messages.length - 1];
    if (!last) return false;
    if (Array.isArray(last.parts)) {
        return last.parts.some((p: any) => p.type === 'file' && p.mediaType?.startsWith('image/'));
    }
    if (Array.isArray(last.experimental_attachments)) {
        return last.experimental_attachments.some((a: any) => a.contentType?.startsWith('image/'));
    }
    return false;
}

function truncate(text: string, max = MAX_MSG_CHARS): string {
    return text.length <= max ? text : text.slice(0, max) + 'â€¦';
}

function toCoreMsgs(messages: any[]): any[] {
    const lastMsg = messages[messages.length - 1];
    const history = messages.slice(0, -1).slice(-MAX_HISTORY_MSGS + 1);
    const trimmed = [...history, lastMsg];

    return trimmed
        .filter((m: any) => m.role === 'user' || m.role === 'assistant')
        .map((m: any) => {
            if (Array.isArray(m.parts) && m.parts.length > 0) {
                const contentParts: any[] = [];
                for (const part of m.parts) {
                    if (part.type === 'text') {
                        const text = truncate(part.text || '');
                        if (text.trim()) contentParts.push({ type: 'text', text });
                    } else if (part.type === 'file') {
                        const url = part.url || '';
                        if (url) contentParts.push({ type: 'image', image: url });
                    }
                }
                if (!contentParts.some((p: any) => p.type === 'text') && m.content) {
                    contentParts.unshift({ type: 'text', text: truncate(m.content) });
                }
                return {
                    role: m.role,
                    content: contentParts.length > 0 ? contentParts : truncate(m.content || ''),
                };
            }
            return { role: m.role, content: truncate(m.content || '') };
        })
        .filter((m: any) => m.content && (typeof m.content === 'string' ? m.content.trim() : m.content.length > 0));
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// HANDLER
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export async function POST(req: NextRequest) {
    let body: any;
    try { body = await req.json(); } catch {
        return new Response("JSON invÃ¡lido.", { status: 400 });
    }

    const messages: any[] = body.messages || [];
    if (!messages.length) return new Response("No messages.", { status: 400 });

    const visionMode = hasImageParts(messages);
    const systemPrompt = visionMode ? VISION_PROMPT : SYSTEM_PROMPT;
    const coreMessages = toCoreMsgs(messages);
    if (coreMessages.length === 0) return new Response("No valid messages.", { status: 400 });

    const modeLabel = visionMode ? 'VISIÃ“N' : 'TEXTO';

    // â”€â”€ Cascade de intentos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // Cada entrada: { label, model }
    // Construimos el array segÃºn las env vars disponibles

    type Attempt = { label: string; model: any };
    const attempts: Attempt[] = [];

    const groqKey = process.env.GROQ_API_KEY;
    const googleKey = process.env.GOOGLE_GENERATIVE_AI_API_KEY;
    const openrouterKey = process.env.OPENROUTER_API_KEY;

    // Groq â€” ultrarrÃ¡pido, gratis, sin tarjeta (IDs verificados vÃ­a API)
    if (groqKey) {
        const groq = createGroq({ apiKey: groqKey });

        if (visionMode) {
            // Llama 4 Maverick: 751 TPS con VISIÃ“N âœ…
            attempts.push({ label: 'Groq/llama-4-maverick [751TPS VISIÃ“N ğŸ”¥]', model: groq('meta-llama/llama-4-maverick-17b-128e-instruct') });
            attempts.push({ label: 'Groq/llama-4-scout [~500TPS VISIÃ“N]', model: groq('meta-llama/llama-4-scout-17b-16e-instruct') });
        } else {
            // GPT-OSS-120B: 3000 TPS, solo texto (sin visiÃ³n) âš¡
            attempts.push({ label: 'Groq/gpt-oss-120b [3000TPS TEXTO âš¡]', model: groq('openai/gpt-oss-120b') });
            attempts.push({ label: 'Groq/llama-4-maverick [751TPS]', model: groq('meta-llama/llama-4-maverick-17b-128e-instruct') });
            attempts.push({ label: 'Groq/llama-3.3-70b [346TPS]', model: groq('llama-3.3-70b-versatile') });
        }
    }

    // 3 â€” Google Gemini directo (237 TPS, gratis, visiÃ³n nativa)
    if (googleKey) {
        const google = createGoogleGenerativeAI({ apiKey: googleKey });
        attempts.push({ label: 'Gemini/2.0-flash-exp [FREE 237TPS]', model: google('gemini-2.0-flash-exp') });
    }

    // 4 & 5 â€” OpenRouter como Ãºltimo recurso
    if (openrouterKey) {
        const openrouter = createOpenRouter({ apiKey: openrouterKey });
        attempts.push({ label: 'OpenRouter/free [FREE]', model: openrouter('openrouter/free') });
        attempts.push({ label: 'OpenRouter/gemini-flash-lite [pago]', model: openrouter('google/gemini-2.0-flash-lite-001') });
    }

    if (attempts.length === 0) {
        return new Response("âŒ No hay API keys configuradas. AgregÃ¡ GROQ_API_KEY o GOOGLE_GENERATIVE_AI_API_KEY en .env", { status: 500 });
    }

    // Intentar cada modelo en orden hasta que uno funcione
    for (let i = 0; i < attempts.length; i++) {
        const { label, model } = attempts[i];
        const isLast = i === attempts.length - 1;

        try {
            const result = streamText({
                model,
                system: systemPrompt,
                messages: coreMessages,
                temperature: 0.3,
                maxOutputTokens: MAX_OUTPUT_TOKENS,
            });

            console.log(`[CEREBRO] â–¶ ${label} | ${modeLabel}`);

            return result.toUIMessageStreamResponse({
                headers: {
                    'Cache-Control': 'no-cache, no-store',
                    'X-Accel-Buffering': 'no',
                    'X-Model-Used': label,
                }
            });

        } catch (error: any) {
            const status = error?.status ?? error?.statusCode;
            const msg = String(error?.message || '');

            // Error fatal de autenticaciÃ³n
            if (status === 401 || msg.includes('User not found') || msg.includes('invalid_api_key')) {
                console.error(`[CEREBRO] âŒ API key invÃ¡lida para ${label}`);
                if (!isLast) continue; // probar siguiente proveedor
                return new Response("âŒ API Key invÃ¡lida.", { status: 401 });
            }

            // Rate limit o no disponible â†’ siguiente
            const isRetryable = status === 429 || status === 503 || status === 502
                || msg.includes('rate limit') || msg.includes('overloaded')
                || msg.includes('unavailable') || msg.includes('quota')
                || msg.includes('model_not_found');

            if ((isRetryable || true) && !isLast) {
                console.warn(`[CEREBRO] âš ï¸ ${label} fallÃ³ (${status ?? msg.slice(0, 60)}). Siguiente...`);
                continue;
            }

            console.error(`[CEREBRO] âŒ Error con ${label}:`, error);
            return new Response(`âŒ Error: ${error.message || 'Error desconocido'}`, { status: 500 });
        }
    }

    return new Response("âŒ Sin modelos disponibles. VerificÃ¡ tus API keys en .env", { status: 503 });
}
